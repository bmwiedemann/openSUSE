From 339ddcd6f26fbd3519f50e96689645da867f6e0f Mon Sep 17 00:00:00 2001
From: Dave Anderson <anderson@redhat.com>
Date: Fri, 24 Apr 2020 14:16:32 -0400
Subject: [PATCH] Several fixes for ARM64 kernels:  (1) Linux kernel patch
 "arm64: mm: Introduce vabits_actual"      introduced "physvirt_offset", which
 is not equal to      (PHYS_OFFSET - PAGE_OFFSET) when KASLR is enabled.     
 physvirt_offset is caculated in arch/arm64/mm/init.c      before
 memstart_addr (PHYS_OFFSET) is randomized.  Let      arm64_VTOP() and
 arm64_PTOV() use physvirt_offset instead,      whose default value is set to
 (phys_offset - page_offset)  (2) For ARM64 RAM dumps without any vmcoreinfo
 and KASLRpassed as      argument, " _stext_vmlinux" is not set.  This causes
 incorrect      calculation of vmalloc_start with VA_BITS_ACTUAL.  (3) For
 ARM64 RAM dumps For ramdumps without vmcoreinfo, get     
 CONFIG_ARM64_VA_BITS from in-kernel config. Without this,      vmemmap size
 is calculated incorrectly.  (4) Fix the vmemmap_start to match with what the
 kernel uses. (vinayakm.list@gmail.com)

References: bsc#1169099
Upstream: 7.2.9
Git-commit: 339ddcd6f26fbd3519f50e96689645da867f6e0f

---
 arm64.c | 40 ++++++++++++++++++++++++++++++++++++----
 defs.h  |  3 ++-
 main.c  |  1 +
 3 files changed, 39 insertions(+), 5 deletions(-)

diff --git a/arm64.c b/arm64.c
index 1285c03dc1cd..653225cd8cd6 100644
--- a/arm64.c
+++ b/arm64.c
@@ -31,6 +31,7 @@ static int arm64_search_for_kimage_voffset(ulong);
 static int verify_kimage_voffset(void);
 static void arm64_calc_kimage_voffset(void);
 static void arm64_calc_phys_offset(void);
+static void arm64_calc_physvirt_offset(void);
 static void arm64_calc_virtual_memory_ranges(void);
 static void arm64_get_section_size_bits(void);
 static int arm64_kdump_phys_base(ulong *);
@@ -364,6 +365,7 @@ arm64_init(int when)
 
 		/* use machdep parameters */
 		arm64_calc_phys_offset();
+		arm64_calc_physvirt_offset();
 	
 		if (CRASHDEBUG(1)) {
 			if (machdep->flags & NEW_VMEMMAP)
@@ -371,6 +373,7 @@ arm64_init(int when)
 					machdep->machspec->kimage_voffset);
 			fprintf(fp, "phys_offset: %lx\n", 
 				machdep->machspec->phys_offset);
+			fprintf(fp, "physvirt_offset: %lx\n", machdep->machspec->physvirt_offset);
 		}
 
 		break;
@@ -477,6 +480,7 @@ arm64_init(int when)
 		arm64_calc_KERNELPACMASK();
 		arm64_calc_phys_offset();
 		machdep->machspec->page_offset = ARM64_PAGE_OFFSET;
+		arm64_calc_physvirt_offset();
 		break;
 	}
 }
@@ -974,6 +978,25 @@ arm64_calc_kimage_voffset(void)
 		ms->kimage_voffset += (kt->relocate * -1);
 }
 
+static void
+arm64_calc_physvirt_offset(void)
+{
+	struct machine_specific *ms = machdep->machspec;
+	ulong physvirt_offset;
+	struct syment *sp;
+
+	ms->physvirt_offset = ms->phys_offset - ms->page_offset;
+
+	if ((sp = kernel_symbol_search("physvirt_offset")) &&
+			machdep->machspec->kimage_voffset) {
+		if (READMEM(pc->mfd, &physvirt_offset, sizeof(physvirt_offset),
+			sp->value, sp->value -
+			machdep->machspec->kimage_voffset) > 0) {
+				ms->physvirt_offset = physvirt_offset;
+		}
+	}
+}
+
 static void
 arm64_calc_phys_offset(void)
 {
@@ -1156,8 +1179,7 @@ arm64_VTOP(ulong addr)
 		}
 
 		if (addr >= machdep->machspec->page_offset)
-			return machdep->machspec->phys_offset
-				+ (addr - machdep->machspec->page_offset);
+			return addr + machdep->machspec->physvirt_offset;
 		else if (machdep->machspec->kimage_voffset)
 			return addr - machdep->machspec->kimage_voffset;
 		else /* no randomness */
@@ -3999,6 +4021,7 @@ arm64_calc_virtual_memory_ranges(void)
 	struct machine_specific *ms = machdep->machspec;
 	ulong value, vmemmap_start, vmemmap_end, vmemmap_size, vmalloc_end;
 	char *string;
+	int ret;
 	ulong PUD_SIZE = UNINITIALIZED;
 
 	if (!machdep->machspec->CONFIG_ARM64_VA_BITS) {
@@ -4006,6 +4029,10 @@ arm64_calc_virtual_memory_ranges(void)
 			value = atol(string);
 			free(string);
 			machdep->machspec->CONFIG_ARM64_VA_BITS = value;
+		} else if (kt->ikconfig_flags & IKCONFIG_AVAIL) {
+			if ((ret = get_kernel_config("CONFIG_ARM64_VA_BITS",
+					&string)) == IKCONFIG_STR)
+				machdep->machspec->CONFIG_ARM64_VA_BITS = atol(string);
 		}
 	}
 
@@ -4030,9 +4057,14 @@ arm64_calc_virtual_memory_ranges(void)
 #define STRUCT_PAGE_MAX_SHIFT   6
 
 	if (ms->VA_BITS_ACTUAL) {
-		vmemmap_size = (1UL) << (ms->CONFIG_ARM64_VA_BITS - machdep->pageshift - 1 + STRUCT_PAGE_MAX_SHIFT);
+		ulong va_bits_min = 48;
+
+		if (machdep->machspec->CONFIG_ARM64_VA_BITS < 48)
+			va_bits_min = ms->CONFIG_ARM64_VA_BITS;
+
+		vmemmap_size = (1UL) << (va_bits_min - machdep->pageshift - 1 + STRUCT_PAGE_MAX_SHIFT);
 		vmalloc_end = (- PUD_SIZE - vmemmap_size - KILOBYTES(64));
-		vmemmap_start = (-vmemmap_size);
+		vmemmap_start = (-vmemmap_size - MEGABYTES(2));
 		ms->vmalloc_end = vmalloc_end - 1;
 		ms->vmemmap_vaddr = vmemmap_start;
 		ms->vmemmap_end = -1;
diff --git a/defs.h b/defs.h
index d742e8e46500..aba58fff7a1b 100644
--- a/defs.h
+++ b/defs.h
@@ -3031,7 +3031,7 @@ typedef u64 pte_t;
 #define MACHINE_TYPE       "ARM64"    
 
 #define PTOV(X) \
-	((unsigned long)(X)-(machdep->machspec->phys_offset)+(machdep->machspec->page_offset))
+	((unsigned long)(X) - (machdep->machspec->physvirt_offset))
 
 #define VTOP(X)               arm64_VTOP((ulong)(X))
 
@@ -3282,6 +3282,7 @@ struct machine_specific {
 	ulong CONFIG_ARM64_VA_BITS;
 	ulong VA_START;
 	ulong CONFIG_ARM64_KERNELPACMASK;
+	ulong physvirt_offset;
 };
 
 struct arm64_stackframe {
diff --git a/main.c b/main.c
index e04f28d8c98f..7f562e69d3c1 100644
--- a/main.c
+++ b/main.c
@@ -244,6 +244,7 @@ main(int argc, char **argv)
 					kt->relocate *= -1;
 					kt->flags |= RELOC_SET;
 					kt->flags2 |= KASLR;
+					st->_stext_vmlinux = UNINITIALIZED;
 				}
 
 			} else if (STREQ(long_options[option_index].name, "reloc")) {
-- 
2.26.2

