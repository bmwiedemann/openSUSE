<revisionlist>
  <revision rev="1" vrev="1">
    <srcmd5>8eac4d03e85bbe44675eeff8fa3fe401</srcmd5>
    <version>1.3.0</version>
    <time>1601997183</time>
    <user>dimstar_suse</user>
    <comment> </comment>
    <requestid>839729</requestid>
  </revision>
  <revision rev="2" vrev="2">
    <srcmd5>a4647df061ea06688bfbe4d3f9ec4e27</srcmd5>
    <version>1.3.0</version>
    <time>1611068605</time>
    <user>dimstar_suse</user>
    <comment></comment>
    <requestid>864286</requestid>
  </revision>
  <revision rev="3" vrev="3">
    <srcmd5>ca874f673d2b31cbe6ccaa023e8fdc94</srcmd5>
    <version>1.3.0</version>
    <time>1612707650</time>
    <user>dimstar_suse</user>
    <comment></comment>
    <requestid>869859</requestid>
  </revision>
  <revision rev="4" vrev="1">
    <srcmd5>3a909478ce054196a4364c6584c7e096</srcmd5>
    <version>1.4.2</version>
    <time>1674927853</time>
    <user>dimstar_suse</user>
    <comment></comment>
    <requestid>1061576</requestid>
  </revision>
  <revision rev="5" vrev="2">
    <srcmd5>94dcbe0377874115b43007fb54fd87b7</srcmd5>
    <version>1.4.2</version>
    <time>1675357739</time>
    <user>dimstar_suse</user>
    <comment>- upgrade opt-einsum to requires as it is imported by tensor/
  unconditionally</comment>
    <requestid>1062607</requestid>
  </revision>
  <revision rev="6" vrev="3">
    <srcmd5>139891b56ba0850beb87b0f57896a0d2</srcmd5>
    <version>1.4.2</version>
    <time>1679766929</time>
    <user>dimstar_suse</user>
    <comment></comment>
    <requestid>1074164</requestid>
  </revision>
  <revision rev="7" vrev="4">
    <srcmd5>ccbe4600891b530818e7737624310f1d</srcmd5>
    <version>1.4.2</version>
    <time>1686171995</time>
    <user>dimstar_suse</user>
    <comment>- Numba now exists for Python 3.11, stop skipping it.</comment>
    <requestid>1090173</requestid>
  </revision>
  <revision rev="8" vrev="1">
    <srcmd5>9a2000990df1c8e7b188cecdf4f3d622</srcmd5>
    <version>1.7.3</version>
    <time>1709332575</time>
    <user>dimstar_suse</user>
    <comment>Forwarded request #1152767 from bnavigator

- Update to 1.7.3
   ## Enhancements:
    * qu.randn: support dist=&quot;rademacher&quot;.
    * support dist and other randn options in various TN builders.
    ## Bug fixes:
    * restore fallback (to scipy.linalg.svd with driver='gesvd')
      behavior for truncated SVD with numpy backend.
  - Release 1.7.2
    ## Bug fixes:
    * removed import of deprecated numba.generated_jit decorator.
    ## Enhancements:
    * add normalized=True option to tensor_network_distance for
      computing the normalized distance between tensor networks,
      which is useful for convergence checks.
      Tensor.distance_normalized and
      TensorNetwork.distance_normalized added as aliases.
    * add TensorNetwork.cut_bond for cutting a bond index
  - Release v1.7.1
    ## Enhancements:
    * add TensorNetwork.visualize_tensors for visualizing the actual
      data entries of an entire tensor network.
    * add ham.build_mpo_propagator_trotterized for building a
      trotterized propagator from a local 1D hamiltonian. This also
      includes updates for creating 'empty' tensor networks using
      TensorNetwork.new, and building up gates from empty tensor
      networks using TensorNetwork.gate_inds_with_tn.
    * add more options to Tensor.expand_ind and Tensor.new_ind:
      repeat tiling mode and random padding mode.
    * tensor decomposition: make eigh_truncated backend agnostic.
    * tensor_compress_bond: add reduced=&quot;left&quot; and reduced=&quot;right&quot;</comment>
    <requestid>1153130</requestid>
  </revision>
  <revision rev="9" vrev="1">
    <srcmd5>f44c49c5798d815fcd7b648402d741f4</srcmd5>
    <version>1.8.4</version>
    <time>1725275675</time>
    <user>dimstar_suse</user>
    <comment>- update to 1.8.4:
  * support for numpy v2.0 and scipy v1.14
  * add MPS sampling: `MatrixProductState.sample_configuration`
    and `MatrixProductState.sample` (generating multiple samples)
    and use these for `CircuitMPS.sample` and
    `CircuitPermMPS.sample`.
  * add basic `.plot()` method for SimpleUpdate classes
  * add `edges_1d_chain` for generating 1D chain edges
  * operatorbuilder: better coefficient placement for long range
    MPO building
  * `TNOptimizer` can now accept an arbitrary pytree (nested
    combination of dicts, lists, tuples, etc. with
    `TensorNetwork`, `Tensor` or raw `array_like` objects as the
    leaves) as the target object to optimize.
  * `TNOptimizer` can now directly optimize `Circuit` objects,
    returning a new optimized circuit with updated parameters.
  * `Circuit`: add `.copy()`, `.get_params()` and `.set_params()`
    interface methods.
  * Update generic TN optimizer docs.
  * add `tn.gen_inds_loops` for generating all loops of indices
    in a TN.
  * add `tn.gen_inds_connected` for generating all connected sets
    of indices in a TN.
  * make SVD fallback error catching more generic ({pull}`#238`)
  * fix some windows + numba CI issues.
  * `approx_spectral_function` add plotting and tracking
  * add dispatching to various tensor primitives to allow
    overriding
  * `CircuitMPS` now supports multi qubit gates, including
    arbitrary multi-controls (which are treated in a low-rank</comment>
    <requestid>1198064</requestid>
  </revision>
  <revision rev="10" vrev="2">
    <srcmd5>aa812ef51a07e5548c40bfcdbd7c695a</srcmd5>
    <version>1.8.4</version>
    <time>1727192038</time>
    <user>anag+factory</user>
    <comment></comment>
    <requestid>1202831</requestid>
  </revision>
  <revision rev="11" vrev="1">
    <srcmd5>b29d112120b5ff2f3d2154d2452d2c0c</srcmd5>
    <version>1.10.0</version>
    <time>1740586973</time>
    <user>dimstar_suse</user>
    <comment>- Update to 1.10.0:
  * Breaking Changes
    + renamed MatrixProductState.partial_trace and MatrixProductState.ptr to
      MatrixProductState.partial_trace_to_mpo to avoid confusion with other
      partial_trace methods that usually produce a dense matrix.
  * Enhancements:
    + tensor network fitting: add method=&quot;tree&quot; for when ansatz is a tree -
      tensor_network_fit_tree
    + tensor network fitting: fix method=&quot;als&quot; for complex networks
    + tensor network fitting: allow method=&quot;als&quot; to use a iterative solver
      suited to much larger tensors, by default a custom conjugate gradient
      implementation.
    + tensor_network_distance and fitting: support hyper indices explicitly
      via output_inds kwarg
    + add tn.make_overlap and tn.overlap for computing the overlap between
      two tensor networks, ⟨ O | T ⟩ , with explicit handling of outer
      indices to address hyper networks. Add output_inds to tn.norm and
      tn.make_norm also, as well as the squared kwarg.
    + replace all numba based paralellism (prange and parallel vectorize)
      with explicit thread pool based parallelism. Should be more reliable
      and no need to set NUMBA_NUM_THREADS anymore. Remove env var
      QUIMB_NUMBA_PAR.
    + Circuit: add dtype and convert_eager options. dtype specifies what the
      computation should be performed in. convert_eager specifies whether to
      apply this (and any to_backend calls) as soon as gates are applied
      (the default for MPS circuit simulation) or just prior to contraction
      (the default for exact contraction simulation).
    + tn.full_simplify: add check_zero (by default set of &quot;auto&quot;) option
      which explicitly checks for zero tensor norms when equalizing norms to
      avoid log10(norm) resulting in -inf or nan. Since it creates a data</comment>
    <requestid>1248539</requestid>
  </revision>
</revisionlist>
