---
 dask/dataframe/backends.py |    2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

--- a/dask/dataframe/backends.py
+++ b/dask/dataframe/backends.py
@@ -352,7 +352,7 @@ class ShuffleGroupResult(SimpleSizeof, d
 @group_split_dispatch.register((pd.DataFrame, pd.Series, pd.Index))
 def group_split_pandas(df, c, k, ignore_index=False):
     indexer, locations = pd._libs.algos.groupsort_indexer(
-        c.astype(np.int64, copy=False), k
+        c.astype(np.intp, copy=False), k
     )
     df2 = df.take(indexer)
     locations = locations.cumsum()
--- a/dask/dataframe/tests/test_dataframe.py
+++ b/dask/dataframe/tests/test_dataframe.py
@@ -3,6 +3,7 @@
 import xml.etree.ElementTree
 from itertools import product
 from operator import add
+import platform
 
 import numpy as np
 import pandas as pd
@@ -3597,6 +3598,12 @@
     # Verbose=False
     buf = StringIO()
     ddf.info(buf=buf, verbose=True)
+
+    if platform.architecture()[0] == "32bit":
+        memory_usage = "312.0"
+    else:
+        memory_usage = "496.0"
+
     expected = (
         "<class 'dask.dataframe.core.DataFrame'>\n"
         "Int64Index: 4 entries, 0 to 3\n"
@@ -3607,7 +3614,7 @@
         " 1   y       4 non-null      category\n"
         " 2   z       4 non-null      object\n"
         "dtypes: category(1), object(1), int64(1)\n"
-        "memory usage: 496.0 bytes\n"
+        "memory usage: {} bytes\n".format(memory_usage)
     )
     assert buf.getvalue() == expected
 