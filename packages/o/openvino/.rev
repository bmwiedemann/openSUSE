<revisionlist>
  <revision rev="1" vrev="1">
    <srcmd5>8e78d6ddd5735947c90f5ef45f630a7f</srcmd5>
    <version>2024.0.0</version>
    <time>1715161167</time>
    <user>dimstar_suse</user>
    <comment> A toolkit for optimizing and deploying AI inference  (fixed license tag from sr#1172510)</comment>
    <requestid>1172596</requestid>
  </revision>
  <revision rev="2" vrev="1">
    <srcmd5>c5273596045220e23a2207c96aeff004</srcmd5>
    <version>2024.1.0</version>
    <time>1715686713</time>
    <user>anag+factory</user>
    <comment>- Fix sample source path in build script:
  * openvino-fix-build-sample-path.patch
- Update to 2024.1.0
- More Generative AI coverage and framework integrations to
  minimize code changes.
  * Mixtral and URLNet models optimized for performance 
    improvements on Intel® Xeon® processors.
  * Stable Diffusion 1.5, ChatGLM3-6B, and Qwen-7B models 
    optimized for improved inference speed on Intel® Core™
    Ultra processors with integrated GPU.
  * Support for Falcon-7B-Instruct, a GenAI Large Language Model
    (LLM) ready-to-use chat/instruct model with superior
    performance metrics.
  * New Jupyter Notebooks added: YOLO V9, YOLO V8
    Oriented Bounding Boxes Detection (OOB), Stable Diffusion 
    in Keras, MobileCLIP, RMBG-v1.4 Background Removal, Magika, 
    TripoSR, AnimateAnyone, LLaVA-Next, and RAG system with 
    OpenVINO and LangChain.
- Broader Large Language Model (LLM) support and more model
  compression techniques.
  * LLM compilation time reduced through additional optimizations
    with compressed embedding. Improved 1st token performance of
    LLMs on 4th and 5th generations of Intel® Xeon® processors 
    with Intel® Advanced Matrix Extensions (Intel® AMX).
  * Better LLM compression and improved performance with oneDNN,
    INT4, and INT8 support for Intel® Arc™ GPUs.
  * Significant memory reduction for select smaller GenAI
    models on Intel® Core™ Ultra processors with integrated GPU.
- More portability and performance to run AI at the edge, 
  in the cloud, or locally.
  * The preview NPU plugin for Intel® Core™ Ultra processors
    is now available in the OpenVINO open-source GitHub 
    repository, in addition to the main OpenVINO package on PyPI.
  * The JavaScript API is now more easily accessible through
    the npm repository, enabling JavaScript developers’ seamless 
    access to the OpenVINO API.
  * FP16 inference on ARM processors now enabled for the 
    Convolutional Neural Network (CNN) by default.
- Support Change and Deprecation Notices
  * Using deprecated features and components is not advised. They
    are available to enable a smooth transition to new solutions 
    and will be discontinued in the future. To keep using 
    Discontinued features, you will have to revert to the last 
    LTS OpenVINO version supporting them.
  * For more details, refer to the OpenVINO Legacy Features 
    and Components page.
  * Discontinued in 2024.0:
    + Runtime components:
      - Intel® Gaussian &amp; Neural Accelerator (Intel® GNA).
        Consider using the Neural Processing Unit (NPU) 
        for low-powered systems like Intel® Core™ Ultra or
        14th generation and beyond.
      - OpenVINO C++/C/Python 1.0 APIs (see 2023.3 API 
        transition guide for reference).
      - All ONNX Frontend legacy API (known as 
        ONNX_IMPORTER_API)
      - 'PerfomanceMode.UNDEFINED' property as part of
         the OpenVINO Python API
    + Tools:
      - Deployment Manager. See installation and deployment
        guides for current distribution options.
      - Accuracy Checker.
      - Post-Training Optimization Tool (POT). Neural Network
        Compression Framework (NNCF) should be used instead.
      - A Git patch for NNCF integration with 
        huggingface/transformers. The recommended approach
        is to use huggingface/optimum-intel for applying 
        NNCF optimization on top of models from Hugging 
        Face.
      - Support for Apache MXNet, Caffe, and Kaldi model 
        formats. Conversion to ONNX may be used as 
        a solution.
  * Deprecated and to be removed in the future:
    + The OpenVINO™ Development Tools package (pip install
      openvino-dev) will be removed from installation options
      and distribution channels beginning with OpenVINO 2025.0.
    + Model Optimizer will be discontinued with OpenVINO 2025.0.
      Consider using the new conversion methods instead. For 
      more details, see the model conversion transition guide.
    + OpenVINO property Affinity API will be discontinued with 
      OpenVINO 2025.0. It will be replaced with CPU binding 
      configurations (ov::hint::enable_cpu_pinning).
    + OpenVINO Model Server components:
      - “auto shape” and “auto batch size” (reshaping a model
        in runtime) will be removed in the future. OpenVINO’s
        dynamic shape models are recommended instead.
</comment>
    <requestid>1173894</requestid>
  </revision>
  <revision rev="3" vrev="1">
    <srcmd5>3d5ae7c7006deb1f3acf38488941ee44</srcmd5>
    <version>2024.2.0</version>
    <time>1718978628</time>
    <user>anag+factory</user>
    <comment></comment>
    <requestid>1181952</requestid>
  </revision>
  <revision rev="4" vrev="2">
    <srcmd5>066c664f7a6f56383b35e343835548cd</srcmd5>
    <version>2024.2.0</version>
    <time>1719349680</time>
    <user>anag+factory</user>
    <comment></comment>
    <requestid>1183106</requestid>
  </revision>
  <revision rev="5" vrev="1">
    <srcmd5>e48f66ac092e5269d1c968fbc97daddd</srcmd5>
    <version>2024.3.0</version>
    <time>1724873451</time>
    <user>dimstar_suse</user>
    <comment></comment>
    <requestid>1196392</requestid>
  </revision>
  <revision rev="6" vrev="1">
    <srcmd5>8bc9cbce32e54b95c9ea18572cd5aaac</srcmd5>
    <version>2024.4.0</version>
    <time>1729183172</time>
    <user>anag+factory</user>
    <comment></comment>
    <requestid>1208543</requestid>
  </revision>
  <revision rev="7" vrev="2">
    <srcmd5>72d47c2b9d06255ede79cf946f7e666c</srcmd5>
    <version>2024.4.0</version>
    <time>1733871004</time>
    <user>anag+factory</user>
    <comment></comment>
    <requestid>1229915</requestid>
  </revision>
  <revision rev="8" vrev="1">
    <srcmd5>9047a76d1d959bf036da093a6f4c93a8</srcmd5>
    <version>2024.6.0</version>
    <time>1736431563</time>
    <user>anag+factory</user>
    <comment></comment>
    <requestid>1235692</requestid>
  </revision>
  <revision rev="9" vrev="1">
    <srcmd5>0b8a4444b95b32c3edf0b29e37ebda97</srcmd5>
    <version>2025.0.0</version>
    <time>1741190539</time>
    <user>anag+factory</user>
    <comment></comment>
    <requestid>1250377</requestid>
  </revision>
  <revision rev="10" vrev="1">
    <srcmd5>6023d05976d4381387a748021823f29d</srcmd5>
    <version>2025.1.0</version>
    <time>1744828810</time>
    <user>anag_factory</user>
    <comment></comment>
    <requestid>1269701</requestid>
  </revision>
  <revision rev="11" vrev="2">
    <srcmd5>347ce55a82ca5e26e4f34781fd2048a4</srcmd5>
    <version>2025.1.0</version>
    <time>1746190739</time>
    <user>dimstar_suse</user>
    <comment></comment>
    <requestid>1273871</requestid>
  </revision>
  <revision rev="12" vrev="3">
    <srcmd5>b878cf5af50dcc1be16ab52879d6eebe</srcmd5>
    <version>2025.1.0</version>
    <time>1746542428</time>
    <user>anag_factory</user>
    <comment></comment>
    <requestid>1274684</requestid>
  </revision>
  <revision rev="13" vrev="4">
    <srcmd5>28291a35f138d764cb44f78a5220c96e</srcmd5>
    <version>2025.1.0</version>
    <time>1748277484</time>
    <user>anag_factory</user>
    <comment></comment>
    <requestid>1279950</requestid>
  </revision>
  <revision rev="14" vrev="1">
    <srcmd5>7619f626f009199afa551b9bb789aef9</srcmd5>
    <version>2025.2.0</version>
    <time>1750790948</time>
    <user>anag_factory</user>
    <comment></comment>
    <requestid>1288134</requestid>
  </revision>
  <revision rev="15" vrev="2">
    <srcmd5>977908d7b9fc8c5177b4beed032d494d</srcmd5>
    <version>2025.2.0</version>
    <time>1750930651</time>
    <user>anag_factory</user>
    <comment></comment>
    <requestid>1288412</requestid>
  </revision>
  <revision rev="16" vrev="1">
    <srcmd5>4580a3536486743f404ada8a0c8e7a57</srcmd5>
    <version>2025.3.0</version>
    <time>1757318244</time>
    <user>anag_factory</user>
    <comment></comment>
    <requestid>1303034</requestid>
  </revision>
</revisionlist>
