<revisionlist>
  <revision rev="1" vrev="1">
    <srcmd5>ecad936eaf52ca8a806407726100bc14</srcmd5>
    <version>0.1.27</version>
    <time>1709070585</time>
    <user>anag+factory</user>
    <comment>New package (see https://lists.opensuse.org/archives/list/factory@lists.opensuse.org/thread/IPU5KGC3JNIDJ5QMKSQITJSCSQ34HLG6/)</comment>
    <requestid>1152310</requestid>
  </revision>
  <revision rev="2" vrev="1">
    <srcmd5>4f3177ee185c1e58cd11573ef8da036e</srcmd5>
    <version>0.1.31</version>
    <time>1713357950</time>
    <user>dimstar_suse</user>
    <comment></comment>
    <requestid>1168439</requestid>
  </revision>
  <revision rev="3" vrev="1">
    <srcmd5>0877b843f6fca11cf3bc0df8fb22201e</srcmd5>
    <version>0.1.32</version>
    <time>1713891440</time>
    <user>anag+factory</user>
    <comment></comment>
    <requestid>1169871</requestid>
  </revision>
  <revision rev="4" vrev="1">
    <srcmd5>20d67f3e88e45aef720fff6ff13b38b1</srcmd5>
    <version>0.1.36</version>
    <time>1715547251</time>
    <user>anag+factory</user>
    <comment></comment>
    <requestid>1173462</requestid>
  </revision>
  <revision rev="5" vrev="1">
    <srcmd5>aca5aa787d9bc929652490663bc020c9</srcmd5>
    <version>0.1.37</version>
    <time>1715615879</time>
    <user>anag+factory</user>
    <comment></comment>
    <requestid>1173543</requestid>
  </revision>
  <revision rev="6" vrev="1">
    <srcmd5>1d84ef8c4cdc49d136cad96aa3f44733</srcmd5>
    <version>0.1.38</version>
    <time>1715969130</time>
    <user>anag+factory</user>
    <comment></comment>
    <requestid>1174685</requestid>
  </revision>
  <revision rev="7" vrev="2">
    <srcmd5>7cdcd43aea6fa4e4e5f9b2ad4481c2f3</srcmd5>
    <version>0.1.38</version>
    <time>1716471311</time>
    <user>anag+factory</user>
    <comment>- Added 15.6 build</comment>
    <requestid>1175956</requestid>
  </revision>
  <revision rev="8" vrev="1">
    <srcmd5>55f08c1bf30f1f3b7a44279fc2f09e63</srcmd5>
    <version>0.1.40</version>
    <time>1717429381</time>
    <user>anag+factory</user>
    <comment>- Update to version 0.1.40:

- Update to version 0.1.39:</comment>
    <requestid>1178089</requestid>
  </revision>
  <revision rev="9" vrev="1">
    <srcmd5>c0316def402e52dc58101771d5b8aa9f</srcmd5>
    <version>0.1.44</version>
    <time>1718743936</time>
    <user>anag+factory</user>
    <comment></comment>
    <requestid>1181491</requestid>
  </revision>
  <revision rev="10" vrev="1">
    <srcmd5>c5b26ec3669102fbf471a5fa72deefb7</srcmd5>
    <version>0.1.45</version>
    <time>1719825574</time>
    <user>dimstar_suse</user>
    <comment>Automatic submission by obs-autosubmit</comment>
    <requestid>1183991</requestid>
  </revision>
  <revision rev="11" vrev="1">
    <srcmd5>8da3e47d0c0b4de3c6090975c8e6380c</srcmd5>
    <version>0.1.48</version>
    <time>1720458505</time>
    <user>anag+factory</user>
    <comment>- Update to version 0.1.48:
  * Fixed issue where Gemma 2 would continuously output when 
    reaching context limits
  * Fixed out of memory and core dump errors when running Gemma 2
  * /show info will now show additional model information in
    ollama run
  * Fixed issue where ollama show would result in an error on 
    certain vision models
- Update to version 0.1.48:
  * Added support for Google Gemma 2 models (9B and 27B)
  * Fixed issues with ollama create when importing from Safetensors
  
- Update to version 0.1.46:
  * Docs (#5149)
  * fix: quantization with template
  * Fix use_mmap parsing for modelfiles
  * Refine mmap default logic on linux
  * Bump latest fedora cuda repo to 39
</comment>
    <requestid>1186033</requestid>
  </revision>
  <revision rev="12" vrev="1">
    <srcmd5>3240dfd45012373263d128e89c602b04</srcmd5>
    <version>0.2.5</version>
    <time>1721065747</time>
    <user>anag+factory</user>
    <comment>- Update to version 0.2.5:
- Update to version 0.2.4:
- Update to version 0.2.3:
- Update to version 0.2.2:
- Update to version 0.2.1:
- Update to version 0.2.0:</comment>
    <requestid>1187407</requestid>
  </revision>
  <revision rev="13" vrev="1">
    <srcmd5>3e96d9d7e53a6024ae40fcdd7f0c8f39</srcmd5>
    <version>0.2.6</version>
    <time>1721395671</time>
    <user>anag+factory</user>
    <comment>- Fixed issue with shared libraries 

- Added %check section
- Use -v when building 
- Update to version 0.2.6:
  * New models: MathÎ£tral is a 7B model designed for math 
    reasoning and scientific discovery by Mistral AI.
  * Fixed issue where uppercase roles such as USER would no longer
    work in the chat endpoints
  * Fixed issue where empty system message would be included in the
    prompt</comment>
    <requestid>1188404</requestid>
  </revision>
  <revision rev="14" vrev="1">
    <srcmd5>c785f08f2a05d36e89afb54eb9285098</srcmd5>
    <version>0.2.8</version>
    <time>1722003322</time>
    <user>dimstar_suse</user>
    <comment></comment>
    <requestid>1189591</requestid>
  </revision>
  <revision rev="15" vrev="1">
    <srcmd5>ccd31114e7ab10648c96270f5c2d63b4</srcmd5>
    <version>0.3.0</version>
    <time>1722180022</time>
    <user>dimstar_suse</user>
    <comment>- Update to version 0.3.0:
  * Ollama now supports tool calling with popular models such
    as Llama 3.1. This enables a model to answer a given prompt
    using tool(s) it knows about, making it possible for models to
    perform more complex tasks or interact with the outside world.
  * New models:
    ~ Llama 3.1
    ~ Mistral Large 2
    ~ Firefunction v2
    ~ Llama-3-Groq-Tool-Use
  * Fixed duplicate error message when running ollama create</comment>
    <requestid>1189982</requestid>
  </revision>
  <revision rev="16" vrev="1">
    <srcmd5>c5a64b16c4973dd44cd2d4a3ca0f3493</srcmd5>
    <version>0.3.1</version>
    <time>1722542687</time>
    <user>dimstar_suse</user>
    <comment></comment>
    <requestid>1190824</requestid>
  </revision>
  <revision rev="17" vrev="1">
    <srcmd5>a53a6b587b797f8b660aeec85032e96c</srcmd5>
    <version>0.3.3</version>
    <time>1722708415</time>
    <user>dimstar_suse</user>
    <comment>- Update to version 0.3.3:
  * The /api/embed endpoint now returns statistics: total_duration,
    load_duration, and prompt_eval_count
  * Added usage metrics to the /v1/embeddings OpenAI compatibility
    API
  * Fixed issue where /api/generate would respond with an empty 
    string if provided a context
  * Fixed issue where /api/generate would return an incorrect 
    value for context
  * /show modefile will now render MESSAGE commands correctly
- Update to version 0.3.2:
  * Fixed issue where ollama pull would not resume download 
    progress
  * Fixed issue where phi3 would report an error on older versions</comment>
    <requestid>1191409</requestid>
  </revision>
  <revision rev="18" vrev="1">
    <srcmd5>b6bdd31c3c210dd407bc2e2432b88e19</srcmd5>
    <version>0.3.6</version>
    <time>1723891290</time>
    <user>dimstar_suse</user>
    <comment>- Update to version 0.3.6:
  * Fixed issue where /api/embed would return an error instead of
    loading the model when the input field was not provided.
  * ollama create can now import Phi-3 models from Safetensors
  * Added progress information to ollama create when importing GGUF
    files
  * Ollama will now import GGUF files faster by minimizing file
    copies
- Update to version 0.3.6:
  * Fixed issue where temporary files would not be cleaned up
  * Fix rare error when Ollama would start up due to invalid model
    data
- Update to version 0.3.4:
 * New embedding models
  - BGE-M3: a large embedding model from BAAI distinguished for 
    its versatility in Multi-Functionality, Multi-Linguality, and 
    Multi-Granularity.
  - BGE-Large: a large embedding model trained in english.
  - Paraphrase-Multilingual: A multilingual embedding model 
    trained on parallel data for 50+ languages.
 * New embedding API with batch support
   - Ollama now supports a new API endpoint /api/embed for 
     embedding generation:
 * This API endpoint supports new features:
   - Batches: generate embeddings for several documents in 
     one request
   - Normalized embeddings: embeddings are now normalized, 
     improving similarity results
   - Truncation: a new truncate parameter that will error if 
     set to false
   - Metrics: responses include load_duration, total_duration and 
     prompt_eval_count metrics
</comment>
    <requestid>1194354</requestid>
  </revision>
  <revision rev="19" vrev="1">
    <srcmd5>530b1dd76c6a4b985ed4e90a057bf50f</srcmd5>
    <version>0.3.10</version>
    <time>1726773464</time>
    <user>anag+factory</user>
    <comment></comment>
    <requestid>1201962</requestid>
  </revision>
  <revision rev="20" vrev="1">
    <srcmd5>6a24117f180c9368896f0cf9dde25632</srcmd5>
    <version>0.3.11</version>
    <time>1726995969</time>
    <user>anag+factory</user>
    <comment></comment>
    <requestid>1202264</requestid>
  </revision>
  <revision rev="21" vrev="1">
    <srcmd5>178e0ebd8c4502f6193fd687e9ccd8d0</srcmd5>
    <version>0.3.12</version>
    <time>1727703627</time>
    <user>anag+factory</user>
    <comment>- Update to version 0.3.12:
  * Llama 3.2: Meta's Llama 3.2 goes small with 1B and 3B 
    models.
  * Qwen 2.5 Coder: The latest series of Code-Specific Qwen 
    models, with significant improvements in code generation, 
    code reasoning, and code fixing.
  * Ollama now supports ARM Windows machines
  * Fixed rare issue where Ollama would report a missing .dll
    file on Windows
  * Fixed performance issue for Windows without GPUs (forwarded request 1204394 from cabelo)</comment>
    <requestid>1204591</requestid>
  </revision>
  <revision rev="22" vrev="1">
    <srcmd5>544c9f36d6b626196a855ce5ef4ff8f7</srcmd5>
    <version>0.3.13</version>
    <time>1728904074</time>
    <user>dimstar_suse</user>
    <comment></comment>
    <requestid>1207827</requestid>
  </revision>
  <revision rev="23" vrev="1">
    <srcmd5>5ace3b839912c7465e114e3ed41d006e</srcmd5>
    <version>0.3.14</version>
    <time>1730387385</time>
    <user>dimstar_suse</user>
    <comment></comment>
    <requestid>1219752</requestid>
  </revision>
  <revision rev="24" vrev="1">
    <srcmd5>0f65c1541dc689f22caa383d9ceab492</srcmd5>
    <version>0.4.0</version>
    <time>1730999825</time>
    <user>dimstar_suse</user>
    <comment></comment>
    <requestid>1222485</requestid>
  </revision>
  <revision rev="25" vrev="1">
    <srcmd5>0095926818f254f31fe619afca8f62d2</srcmd5>
    <version>0.4.2</version>
    <time>1732442691</time>
    <user>anag+factory</user>
    <comment>Automatic submission by obs-autosubmit</comment>
    <requestid>1225993</requestid>
  </revision>
  <revision rev="26" vrev="1">
    <srcmd5>1123bff86c0bccfcada4e8f9af2b4651</srcmd5>
    <version>0.5.1</version>
    <time>1734034695</time>
    <user>anag+factory</user>
    <comment></comment>
    <requestid>1230609</requestid>
  </revision>
  <revision rev="27" vrev="1">
    <srcmd5>406a66bd1c77f7913c612b1b01f3d703</srcmd5>
    <version>0.5.7</version>
    <time>1738163409</time>
    <user>anag+factory</user>
    <comment></comment>
    <requestid>1240594</requestid>
  </revision>
  <revision rev="28" vrev="1">
    <srcmd5>334d419bdf2db0a48afd7bc77d64c8e9</srcmd5>
    <version>0.5.11</version>
    <time>1740247512</time>
    <user>dimstar_suse</user>
    <comment>Automatic submission by obs-autosubmit</comment>
    <requestid>1247774</requestid>
  </revision>
</revisionlist>
