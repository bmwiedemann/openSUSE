<revisionlist>
  <revision rev="1" vrev="1">
    <srcmd5>ecad936eaf52ca8a806407726100bc14</srcmd5>
    <version>0.1.27</version>
    <time>1709070585</time>
    <user>anag+factory</user>
    <comment>New package (see https://lists.opensuse.org/archives/list/factory@lists.opensuse.org/thread/IPU5KGC3JNIDJ5QMKSQITJSCSQ34HLG6/)</comment>
    <requestid>1152310</requestid>
  </revision>
  <revision rev="2" vrev="1">
    <srcmd5>4f3177ee185c1e58cd11573ef8da036e</srcmd5>
    <version>0.1.31</version>
    <time>1713357950</time>
    <user>dimstar_suse</user>
    <comment></comment>
    <requestid>1168439</requestid>
  </revision>
  <revision rev="3" vrev="1">
    <srcmd5>0877b843f6fca11cf3bc0df8fb22201e</srcmd5>
    <version>0.1.32</version>
    <time>1713891440</time>
    <user>anag+factory</user>
    <comment></comment>
    <requestid>1169871</requestid>
  </revision>
  <revision rev="4" vrev="1">
    <srcmd5>20d67f3e88e45aef720fff6ff13b38b1</srcmd5>
    <version>0.1.36</version>
    <time>1715547251</time>
    <user>anag+factory</user>
    <comment></comment>
    <requestid>1173462</requestid>
  </revision>
  <revision rev="5" vrev="1">
    <srcmd5>aca5aa787d9bc929652490663bc020c9</srcmd5>
    <version>0.1.37</version>
    <time>1715615879</time>
    <user>anag+factory</user>
    <comment></comment>
    <requestid>1173543</requestid>
  </revision>
  <revision rev="6" vrev="1">
    <srcmd5>1d84ef8c4cdc49d136cad96aa3f44733</srcmd5>
    <version>0.1.38</version>
    <time>1715969130</time>
    <user>anag+factory</user>
    <comment></comment>
    <requestid>1174685</requestid>
  </revision>
  <revision rev="7" vrev="2">
    <srcmd5>7cdcd43aea6fa4e4e5f9b2ad4481c2f3</srcmd5>
    <version>0.1.38</version>
    <time>1716471311</time>
    <user>anag+factory</user>
    <comment>- Added 15.6 build</comment>
    <requestid>1175956</requestid>
  </revision>
  <revision rev="8" vrev="1">
    <srcmd5>55f08c1bf30f1f3b7a44279fc2f09e63</srcmd5>
    <version>0.1.40</version>
    <time>1717429381</time>
    <user>anag+factory</user>
    <comment>- Update to version 0.1.40:

- Update to version 0.1.39:</comment>
    <requestid>1178089</requestid>
  </revision>
  <revision rev="9" vrev="1">
    <srcmd5>c0316def402e52dc58101771d5b8aa9f</srcmd5>
    <version>0.1.44</version>
    <time>1718743936</time>
    <user>anag+factory</user>
    <comment></comment>
    <requestid>1181491</requestid>
  </revision>
  <revision rev="10" vrev="1">
    <srcmd5>c5b26ec3669102fbf471a5fa72deefb7</srcmd5>
    <version>0.1.45</version>
    <time>1719825574</time>
    <user>dimstar_suse</user>
    <comment>Automatic submission by obs-autosubmit</comment>
    <requestid>1183991</requestid>
  </revision>
  <revision rev="11" vrev="1">
    <srcmd5>8da3e47d0c0b4de3c6090975c8e6380c</srcmd5>
    <version>0.1.48</version>
    <time>1720458505</time>
    <user>anag+factory</user>
    <comment>- Update to version 0.1.48:
  * Fixed issue where Gemma 2 would continuously output when 
    reaching context limits
  * Fixed out of memory and core dump errors when running Gemma 2
  * /show info will now show additional model information in
    ollama run
  * Fixed issue where ollama show would result in an error on 
    certain vision models
- Update to version 0.1.48:
  * Added support for Google Gemma 2 models (9B and 27B)
  * Fixed issues with ollama create when importing from Safetensors
  
- Update to version 0.1.46:
  * Docs (#5149)
  * fix: quantization with template
  * Fix use_mmap parsing for modelfiles
  * Refine mmap default logic on linux
  * Bump latest fedora cuda repo to 39
</comment>
    <requestid>1186033</requestid>
  </revision>
  <revision rev="12" vrev="1">
    <srcmd5>3240dfd45012373263d128e89c602b04</srcmd5>
    <version>0.2.5</version>
    <time>1721065747</time>
    <user>anag+factory</user>
    <comment>- Update to version 0.2.5:
- Update to version 0.2.4:
- Update to version 0.2.3:
- Update to version 0.2.2:
- Update to version 0.2.1:
- Update to version 0.2.0:</comment>
    <requestid>1187407</requestid>
  </revision>
  <revision rev="13" vrev="1">
    <srcmd5>3e96d9d7e53a6024ae40fcdd7f0c8f39</srcmd5>
    <version>0.2.6</version>
    <time>1721395671</time>
    <user>anag+factory</user>
    <comment>- Fixed issue with shared libraries 

- Added %check section
- Use -v when building 
- Update to version 0.2.6:
  * New models: MathÎ£tral is a 7B model designed for math 
    reasoning and scientific discovery by Mistral AI.
  * Fixed issue where uppercase roles such as USER would no longer
    work in the chat endpoints
  * Fixed issue where empty system message would be included in the
    prompt</comment>
    <requestid>1188404</requestid>
  </revision>
  <revision rev="14" vrev="1">
    <srcmd5>c785f08f2a05d36e89afb54eb9285098</srcmd5>
    <version>0.2.8</version>
    <time>1722003322</time>
    <user>dimstar_suse</user>
    <comment></comment>
    <requestid>1189591</requestid>
  </revision>
  <revision rev="15" vrev="1">
    <srcmd5>ccd31114e7ab10648c96270f5c2d63b4</srcmd5>
    <version>0.3.0</version>
    <time>1722180022</time>
    <user>dimstar_suse</user>
    <comment>- Update to version 0.3.0:
  * Ollama now supports tool calling with popular models such
    as Llama 3.1. This enables a model to answer a given prompt
    using tool(s) it knows about, making it possible for models to
    perform more complex tasks or interact with the outside world.
  * New models:
    ~ Llama 3.1
    ~ Mistral Large 2
    ~ Firefunction v2
    ~ Llama-3-Groq-Tool-Use
  * Fixed duplicate error message when running ollama create</comment>
    <requestid>1189982</requestid>
  </revision>
  <revision rev="16" vrev="1">
    <srcmd5>c5a64b16c4973dd44cd2d4a3ca0f3493</srcmd5>
    <version>0.3.1</version>
    <time>1722542687</time>
    <user>dimstar_suse</user>
    <comment></comment>
    <requestid>1190824</requestid>
  </revision>
  <revision rev="17" vrev="1">
    <srcmd5>a53a6b587b797f8b660aeec85032e96c</srcmd5>
    <version>0.3.3</version>
    <time>1722708415</time>
    <user>dimstar_suse</user>
    <comment>- Update to version 0.3.3:
  * The /api/embed endpoint now returns statistics: total_duration,
    load_duration, and prompt_eval_count
  * Added usage metrics to the /v1/embeddings OpenAI compatibility
    API
  * Fixed issue where /api/generate would respond with an empty 
    string if provided a context
  * Fixed issue where /api/generate would return an incorrect 
    value for context
  * /show modefile will now render MESSAGE commands correctly
- Update to version 0.3.2:
  * Fixed issue where ollama pull would not resume download 
    progress
  * Fixed issue where phi3 would report an error on older versions</comment>
    <requestid>1191409</requestid>
  </revision>
</revisionlist>
