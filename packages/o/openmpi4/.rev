<revisionlist>
  <revision rev="1" vrev="1">
    <srcmd5>ef2426b5c93ada70c1e9d8bd74b694cd</srcmd5>
    <version>4.0.2</version>
    <time>1584744961</time>
    <user>dimstar_suse</user>
    <comment>Add openmpi4 package</comment>
    <requestid>786504</requestid>
  </revision>
  <revision rev="2" vrev="1">
    <srcmd5>a6576d5433286248d71397b3bd9eb652</srcmd5>
    <version>4.0.3</version>
    <time>1591743080</time>
    <user>dimstar_suse</user>
    <comment></comment>
    <requestid>812864</requestid>
  </revision>
  <revision rev="3" vrev="1">
    <srcmd5>21657b7fd10071ff9fea5de3278d1956</srcmd5>
    <version>4.0.4</version>
    <time>1591990948</time>
    <user>dimstar_suse</user>
    <comment></comment>
    <requestid>814028</requestid>
  </revision>
  <revision rev="4" vrev="1">
    <srcmd5>ab3c2dc41f5c36d6f4f864b95ffe6504</srcmd5>
    <version>4.0.5</version>
    <time>1601919747</time>
    <user>dimstar_suse</user>
    <comment></comment>
    <requestid>839582</requestid>
  </revision>
  <revision rev="5" vrev="1">
    <srcmd5>9aedee9dfba3c7eee53c785030172286</srcmd5>
    <version>4.1.0</version>
    <time>1617279454</time>
    <user>RBrownSUSE</user>
    <comment>- Update to version 4.1.0
  * collectives: Add HAN and ADAPT adaptive collectives components.
    Both components are off by default and can be enabled by specifying
    &quot;mpirun --mca coll_adapt_priority 100 --mca coll_han_priority 100 ...&quot;.
    We intend to enable both by default in Open MPI 5.0.
  * OMPIO is now the default for MPI-IO on all filesystems, including
    Lustre (prior to this, ROMIO was the default for Lustre).  Many
    thanks to Mark Dixon for identifying MPI I/O issues and providing
    access to Lustre systems for testing.
  * Minor MPI one-sided RDMA performance improvements.
  * Fix hcoll MPI_SCATTERV with MPI_IN_PLACE.
  * Add AVX support for MPI collectives.
  * Updates to mpirun(1) about &quot;slots&quot; and PE=x values.
  * Fix buffer allocation for large environment variables.  Thanks to
    @zrss for reporting the issue.
  * Upgrade the embedded OpenPMIx to v3.2.2.
  * Fix issue with extra-long values in MCA files.  Thanks to GitHub
    user @zrss for bringing the issue to our attention.
  * UCX: Fix zero-sized datatype transfers.
  * Fix --cpu-list for non-uniform modes.
  * Fix issue in PMIx callback caused by missing memory barrier on Arm platforms.
  * OFI MTL: Various bug fixes.
  * Fixed issue where MPI_TYPE_CREATE_RESIZED would create a datatype
    with unexpected extent on oddly-aligned datatypes.
  * collectives: Adjust default tuning thresholds for many collective
    algorithms
  * runtime: fix situation where rank-by argument does not work
  * Portals4: Clean up error handling corner cases
  * runtime: Remove --enable-install-libpmix option, which has not
    worked since it was added
  * UCX: Allow UCX 1.8 to be used with the btl uct
  * UCX: Replace usage of the deprecated NB API of UCX with NBX
  * OMPIO: Add support for the IME file system
  * OFI/libfabric: Added support for multiple NICs
  * OFI/libfabric: Added support for Scalable Endpoints
  * OFI/libfabric: Added btl for one-sided support
  * OFI/libfabric: Multiple small bugfixes
  * libnbc: Adding numerous performance-improving algorithms
- Removed: reproducible.patch - replaced by spec file settings.</comment>
    <requestid>882294</requestid>
  </revision>
</revisionlist>
