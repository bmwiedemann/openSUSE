-------------------------------------------------------------------
Wed Feb 05 08:41:57 UTC 2025 - fredrik.lonnegren@suse.com

- Update to version 1.0.9:
  * versions: Synchronize crate versions to the latest used
  * scx_lavd: Use BPF CO-RE for SCX_ENQ_CPU_SELECTED
  * scx_layered: make gpu poll interval configurable
  * scx_prev: a simple scheduler tested on OLTP workloads
  * scx_lavd: Don't try preemption for greedy tasks
  * scxtop: Add trace options
  * scx_central: alert for 'silly' values for the chosen cpu from command line.
  * scx_lavd: Preemption when ops.select_cpu() was skipped
  * scxtop: Add support for generating perfetto traces
  * scx_bpfland: enable task preemption
  * scx_layered: add gpu matcher
  * rust schedulers: for sibling cpu using static dispatch instead.
  * scx_bpfland: reduce heap allocation with energy profile/primary domain.
  * scx_bpfland: Mark --local-kthreads/-k as experimental
  * scx_loader: Update performance profiles for scx_bpfland
  * scxtop: Fix layout for sparklines
  * scxtop: Add scx_stats support
  * scx_lavd: Conder the hardware resource sharing level in CPU ordering
  * scxtop: Fill render area by setting max events
  * scxtop: Add event to default list after selection
  * scx_layered: fixes for MATCH_SCXCMD_JOIN
  * scxtop: Fix scroll on page up
  * scxtop: update help display with last changes (perf event scrolling).
  * scx_bpfland: Introduce --cpufreq to enable CPU frequency scaling
  * scx_bpfland: Introduce --local-pcpu to prioritize per-CPU tasks
  * scx_bpfland: Get rid of the interactive task classification via nvcsw
  * scx_bpfland: Allow tasks to overflow primary domain more aggressively
  * scx_bpfland: Virtual deadline with partial execution vruntime
  * scx_bpfland: Do not scale slice lag with the task weight
  * scx_bpfland: Set max performance level with balance_performance
  * scx_lavd: Direct dispatch at ops.enqueue()
  * scx_lavd: Do not reserve an idle cpu at ops.enqueue()
  * scx_loader: Avoid race condition with start_scheduler
  * scx_lavd: Use time_delta() for clock difference calculation
  * scxtop: Add ability to select perf events
  * scxtop: proposing to add bus-cycles event.
  * scx_layered: add 'join layer' command
  * scx_central: fix cpu affinity corrupted allocation (glibc).
  * scx_rusty: fix custom PartialOrd implementation build warning.
  * scx_layered: Fix dump_layer_cpumask()
  * scx_rustland_core: fix static mutable reference usage warning (BUF).
  * scxtop: Collect uncore frequency
  * scx_rusty: use lb_domain naming for load balancing domains
  * scxtop: Fix node barchart
  * scx_bpfland: avoid starvation of per-CPU tasks
  * scxtop: Fix attach on newer kernels
  * scxtop: Add CPU frequency to default sparkline view
  * scxtop: Add barchart to node view
  * scx_bpfland: re-enqueue tasks when a CPU is taken by a higher sched class
  * scx_bpfland: give queued tasks a chance to run on the same CPU
  * scx_bpfland: do not dispatch per-CPU kthreads directly by default
  * scx_bpfland: proactively wake idle CPUs after task enqueue
  * scx_layered: Add pid namespace layer matching
  * scx_bpfland: do not allow per-CPU kthread to preempt other tasks
  * scxtop: Add scheduler view to llc/node views
  * scx_lavd: Add a fast path for a migration-disabled task in pick_idle_cpu()
  * scxtop: Add scxtop tui
  * scx_flash: prevent scheduling bubbles on kernels >= 6.12
  * scx_rusty: prevent scheduling bubbles on kernels >= 6.12
  * scx_bpfland: use nvcsw metrics only for cpufreq scaling
  * scx_bpfland: evaluate deadline based on vruntime and task's sum_vruntime
  * scx_bpfland: consider sum_runtime instead of avg_runtime
  * scx_bpfland: never actively wake-up idle CPUs
  * scx_flash: Option for userspace lock boosting
  * scx_bpfland: support !CONFIG_SMP kernels
  * scx_rusty: use arena allocations instead of maps for tasks
  * scx_rusty: use map to manage task masks
  * scx_layered: Fix multplication overflows
  * scx_layered: Improve open layer prot[_preempt] accounting
  * scx_layered: Don't apply preempt protection between two open layers
  * scx_layered: Disable owner protection for preempt layers
  * scx_rusty: remove per-task temp mask and replace with per-CPU singleton
  * scx_layered: Implement layer property disallow_preempt_after_us
  * scx_lavd: Prioritize a migration-disabled task
  * scx_lavd: Ensure to check all compute domains when task stealing
  * scx_lavd: Kick an idle cpu as early as possible on ops.select_cpu()
  * scx_lavd: Change the default time slice to 5 msec
  * scx_lavd: Add a fast path to pick_idle_cpu() when overloaded
  * scx_lavd: Turn on frequency scaling in performance mode
  * scx_lavd: Properly reinitialize cpumask for autopilot mode
  * scx_rustland_core: Select any idle CPU when task affinity changes

-------------------------------------------------------------------
Tue Dec 17 09:35:57 UTC 2024 - fredrik.lonnegren@suse.com

- Update to version 1.0.8:
  * scx_layered: Put all tasks with custom affinities into the hi fallback DSQs
  * scx_bpfland: do not rely on scx_utils::autopower
  * scx_layered: Make low fallback DSQs useful and other changes
  * scx_layered: handle nr_to_free calculation
  * scx_layered: Implement empty LLC draining
  * scx_layered: queued_runtime tracking bug fix and disable xllc_mig_min_us
  * scx_bpfland: server workload improvements
  * scx_loader: add mode for server-oriented workloads
  * scx_layered: Improve layer core growth algos
  * scx_layered: Make layered work in pid namespaces
  * scx_loader: fix recursion of type convertion
  * scx_layered: Add pid namespace layer matching

-------------------------------------------------------------------
Sat Dec 07 13:29:51 UTC 2024 - fredrik.lonnegren@suse.com

- Update to version 1.0.7:
  * scx_layered: Add fallback DSQ cost accounting
  * scx_layered: Fix verifier issue when tracing
  * scx_lavd: update cur_logical_clk atomically
  * scx_loader: tune scx_bpfland default options
  * scx_layered: Fix verifier issue on older kernels
  * scx_layered: Use layer idle_smt option
  * scx_layered: Add fallback costs to dump
  * scx_layered: Work around older kernels choking on function calls
  * scx_layered: add timer antistall
  * scx_layered: Fix error in dispatch consumption
  * scx_layered: Add helper for layer slice duration
  * scx_layered: Fix cost accounting for fallback dsqs
  * scx_layered: Consume from local LLCs for dispatch
  * scheds: introduce scx_flash
  * scx_layered: Perf improvements and a bug fix
  * scx_layered: Don't limit antistall execution to layered_cpumask
  * scx_layered: Fix verifier issues on older kernels
  * scx_layered: Cleanups around topology handling
  * scx_lavd: Factor the task's runtime more aggressively in a deadline
    calculation
  * scx_layered: Work around verification failure in antistall_set()
  * scx_loader: add scx_flash as supported scheduler
  * scx_layered: Add netdev IRQ balancing
  * scx_layered: Use PROG_RUN for cpumask updates
  * scx_lavd: Optimize the layout of struct task_ctx
  * scx_layered: Remove high fallback dsq budget check
  * scx_lavd: Do not exclude exiting tasks
  * scx_rustland_core: proactively wake up CPUs when selected by user space
  * scx_layered: Reimplement CPU allocation and some other fixes
  * scx_rusty: Fix verifier errors on older kernels
  * scx_layered: select_cpu() fixes and updates
  * scx_lavd: Boost time slice more generously
  * scx_lavd: Optimize performance criticality calculation
  * scx_lavd: Optimize the cpuc_ctx layout for cache friendliness
  * scx_lavd: Optimize preemption
  * scx_bpfland: restart on energy profile change
  * scx_lavd: add tunables for adjusting time slices
  * scx_layered: Track owned/open execution times and per-LLC-layer stats
  * scx_loader: restart scheduler upon fail
  * scx_lavd: Limit the slice extension of a lock holder
  * scx_layered: Implement in-layer execution protection to replace cost based
    fairness
  * scx_bpfland: dump cache_id_map in ascending order
  * scx_layered: Fix idle selection on big/little
  * scx_layered: Prioritize sched userspace and fix owned execution protection
  * scx_layered: State tracking updates and layer sizing related fixes
  * scx_lavd: Load balancing across compute domains
  * scx_layered: Deprecate idle_smt layer config
  * scx_lavd: Fetch active profile from power-profiles-daemon dbus interface
    when using autopower
  * scx_layered: Make vtime_now per-LLC
  * scx_layered: Implement layer config xllc_mig_min_us
  * scx_utils: Extend topology to support Snapdragon X Elite
  * scx_rusty: Refactor access operation of nodemask
  * scx_stats,scx_lavd: describe non-nested stats meta
  * scx_lavd: Reset per-CPU preemption information when a CPU is released
  * scx_layered: Fix vtime and llc_id handling bugs
  * scx_layered: Fix a silly bug in select_cpu() and implement per-layer fifo
    mode

-------------------------------------------------------------------
Mon Nov 18 15:49:21 UTC 2024 - fredrik.lonnegren@suse.com

- Update to version 1.0.6:
  * scx_lavd: support CPU hotplug correctly
  * scx_rusty: fix single dom short-circuit
  * scx_layered: Add per layer time slices to stats
  * scx_layered: Refactor topology algorithms to a separate module
  * scx_layered: Add per layer weights
  * scx_bpfland: rework lowlatency mode
  * scx_layered: Add big cpumask
  * scx_layered: Use idle smt mask for idle selection
  * scx_layered: Improve perf on non topo aware paths
  * scx_rusty: Fix BPF crash during CPU hotplug
  * scx_layered: Update idle topology selection order
  * scx_layered: lighten/reduce nested loops in layered dispatch
  * scx_layered: Add stress-ng example layer
  * scx_layered: Make stress-ng non exclusive in example
  * scx_bpfland: prevent per-CPU DSQ stall with per-CPU kthreads
  * scx_layered: enable configuring layer iteration when no topo
  * [rusty] Fix load stats when host is under-utilized
  * scx_layered: Update CI to show stats
  * layered: split dispatch into no_topo version
  * scx_layered: Rename load_adj statistic
  * layered: attempt to work steal from own llc before others
  * scx_layered: Fix verifier errors
  * scx_layered: Cleanup debug messages
  * scx_bpfland: fix cpumask initialization error
  * scx_layered: Change default DSQ iter algo
  * scx_layered: Cleanup topology preempt path
  * scx_layered: Implement reverse weight DSQ algorithm
  * scx_layered: make default value for disable_topology dynamic
  * scx_lavd: mitigate the lock holder preemption problem
  * scx_rustland_core: use handle_mm_fault kprobe
  * scx_bpfland: drop per-cpu DSQs
  * scx_lavd: do not inspect scx_lavd process itself
  * scx_layered: Remove layer iteration
  * scx_mitosis: handle enqueue() on !wakeup
  * scx_mitosis: Handle pinned tasks
  * scx_layered: add RandomTopo layer growth algorithm
  * scx_layered: make disable_topology arg require equals
  * scx_bpfland: rework lowlatency mode
  * scx_layered: Fix crash on aarch64 due to unavailable cache id file
  * scx_lavd: add missing reset_lock_futex_boost()
  * scx_rustland: Adjust task's vruntime budget based on latency weight
  * scx_layered: fix exit_task ctx lookup err
  * scx_lavd: fix/work around a verifier error
  * scx_lavd: various optimizations for more consistent performance
  * scx_loader: introduce configuration
  * scx_layered: Add monitor
  * scx_layered: Fix declarations in timer
  * scx_lavd: fix uninitialized memory access at comp_preemption_info()
  * scx_layered: support verifying on older kernels and fix logic
  * scx_layered: Add cost accounting
  * scx_lavd: optimize preemption
  * scx_layered: Refactor dispatch
  * scx_lavd: tuning and optimizing latency criticality calculation
  * scx_layered: Add layer name to bpf
  * scx_layered: Add layer CPU cost to dump
  * scx_lavd: Correct the type of taskc within lavd_dispatch()
  * scx_lavd: optimize ops.dispatch() and DSQ placement
  * scx_layered: Fix dump output format
  * scx_layered: Add additional drain to fallback DSQs
  * scx_layered: Fix trace format
  * scx_layered: point costc to global struct when initializing budgets
  * scx_lavd: entirely drop kernel lock tracing
  * scx_rusty: Restore push domain tasks when no task found
  * scx_lavd: fix a performance regression bug 
    (perf bench -f simple sched messaging)

-------------------------------------------------------------------
Tue Oct 29 18:02:44 UTC 2024 - Fredrik Lönnegren <fredrik.lonnegren@suse.com>

- Move scx-<version>.tar.zst to buildtime service.

-------------------------------------------------------------------
Tue Oct 22 08:48:50 UTC 2024 - Fredrik Lönnegren <fredrik.lonnegren@suse.com>

- Add devel package that includes the common headers from the upstream
  repository.

-------------------------------------------------------------------
Thu Oct  3 19:00:46 UTC 2024 - Fredrik Lönnegren <fredrik.lonnegren@suse.com>

- Update to v1.0.5:
  * scx_rustland_core: introduce topology awareness
  * scx_layered: clean up Layer::new layer_growth_algo
  * scx_lavd: improve greedy ratio calculation and more
  * scx_rustland_core: move includes back to the lib section
  * scx_bpfland: use sum_exec_runtime to evaluate task's used time slice
  * scx_layered: Fix typo in stats
  * scx_layered: Pass layer spec for core growth algo
  * scx_rusty: init domains when calculating averages
  * scx_layered: Add random layer growth algo by
  * scx_layered: Add topology aware core growth selection
  * scx_layered: Add stats for XNUMA/XLLC migrations
  * scx_lavd: add a short circuit for the case of no turbo core
  * scx_lavd: boost the latency-criticality of kernel threads
  * scx_bpfland: refine idle CPU selection logic
  * scx_layered: add round robin growth strategy
  * scxstats_to_openmetrics: fix format string
  * scx_rustland_core: improve idle CPU selection API and logic
  * scx_rustland_core: prevent CI failures
  * scx_rustland_core: Access the returned value of saturating_sub()
  * scx_layered: Refactor match_layer() and implement helper function to access
    cpumask within bpf_cpumask
  * scx_bpfland: Remove the usage of cast_mask in bpfland_enqueue
  * scx_lavd: consider waker's CPU when ops.select_cpu()
  * scx_layered: Add a hi fallback dsq per llc
  * scx_layered: Add Big/Little core growth algos
  * scx_layered: Add topology aware preemption
  * scx_lavd: find a victim cpu for preemption within task's compute domain
  * scx_layered: Add waker stats per layer
  * scx_layered: Cleanup dump format
  * scx_lavd: propagate waker's latency criticality to its wakee
  * scx_layered: Restrict preemption to layer cpumask
  * scx_layered: Make layered idle CPU selection topology aware
  * scx_rustland_core: fix mm stall
  * scx_loader: Add initial automatic scheduler switching via --monitor-no-dbus
  * scx_layered: Add layer growth algo to layer bpf config
  * Sync from kernel and re-enable scx_flatcg and scx_pair
  * scx_layered: Fix idle core selection
  * scx_loader: Add systemd service and on-DBUS launch
  * scx_lavd: more accurately determine the performance criticality threshold
  * scx_lavd: fix two potential bugs
  * scx_layered: Fix cache initialization
  * Revert "scx_rustland_core: prevent deadlock with per-CPU DSQs and CPU
  * scx_bpfland small fixes and improvements
  * scx_stats: Implement macro #stat_doc to autogen doc from stat desc
  * scx_lavd: Fix typo

