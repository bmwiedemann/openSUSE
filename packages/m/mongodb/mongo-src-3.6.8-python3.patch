diff --git a/SConstruct b/SConstruct
index 188927e..778d928 100644
--- a/SConstruct
+++ b/SConstruct
@@ -389,7 +389,7 @@ win_version_min_choices = {
 }
 
 add_option('win-version-min',
-    choices=win_version_min_choices.keys(),
+    choices=list(win_version_min_choices.keys()),
     default=None,
     help='minimum Windows version to support',
     type='choice',
@@ -498,7 +498,7 @@ except ValueError as e:
 def variable_shlex_converter(val):
     # If the argument is something other than a string, propogate
     # it literally.
-    if not isinstance(val, basestring):
+    if not isinstance(val, str):
         return val
     parse_mode = get_option('variable-parse-mode')
     if parse_mode == 'auto':
@@ -752,7 +752,8 @@ env_vars.Add('TOOLS',
 
 env_vars.Add('VARIANT_DIR',
     help='Sets the name (or generator function) for the variant directory',
-    default=mongo_generators.default_variant_dir_generator,
+#    default=mongo_generators.default_variant_dir_generator,
+    default="blah",
 )
 
 env_vars.Add('VERBOSE',
@@ -827,7 +828,7 @@ SConsignFile(str(sconsDataDir.File('sconsign')))
 def printLocalInfo():
     import sys, SCons
     print( "scons version: " + SCons.__version__ )
-    print( "python version: " + " ".join( [ `i` for i in sys.version_info ] ) )
+    print( "python version: " + " ".join( [ str(i) for i in sys.version_info ] ) )
 
 printLocalInfo()
 
@@ -1918,7 +1919,7 @@ def doConfigure(myenv):
         # to make them real errors.
         cloned.Append(CCFLAGS=['-Werror'])
         conf = Configure(cloned, help=False, custom_tests = {
-                'CheckFlag' : lambda(ctx) : CheckFlagTest(ctx, tool, extension, flag)
+                'CheckFlag' : lambda ctx : CheckFlagTest(ctx, tool, extension, flag)
         })
         available = conf.CheckFlag()
         conf.Finish()
diff --git a/buildscripts/aggregate_tracefiles.py b/buildscripts/aggregate_tracefiles.py
index 8f1db78..0b4bfd2 100644
--- a/buildscripts/aggregate_tracefiles.py
+++ b/buildscripts/aggregate_tracefiles.py
@@ -16,7 +16,7 @@ def aggregate(inputs, output):
 
     args += ['-o', output]
 
-    print ' '.join(args)
+    print(' '.join(args))
     
     return subprocess.call(args)  
 
diff --git a/buildscripts/burn_in_tests.py b/buildscripts/burn_in_tests.py
index a78c905..6c4b852 100644
--- a/buildscripts/burn_in_tests.py
+++ b/buildscripts/burn_in_tests.py
@@ -161,7 +161,7 @@ def find_changed_tests(branch_name, base_commit, max_revisions, buildvariant, ch
             # commit among 'revs_to_check' that's been activated in Evergreen. We handle this by
             # only considering tests changed in the current commit.
             last_activated = "HEAD"
-        print "Comparing current branch against", last_activated
+        print("Comparing current branch against", last_activated)
         revisions = callo(["git", "rev-list", base_commit + "..." + last_activated]).splitlines()
         base_commit = last_activated
     else:
@@ -169,10 +169,10 @@ def find_changed_tests(branch_name, base_commit, max_revisions, buildvariant, ch
 
     revision_count = len(revisions)
     if revision_count > max_revisions:
-        print "There are too many revisions included (%d)." % revision_count, \
+        print("There are too many revisions included (%d)." % revision_count, \
               "This is likely because your base branch is not " + branch_name + ".", \
               "You can allow us to review more than 25 revisions by using", \
-              "the --maxRevisions option."
+              "the --maxRevisions option.")
         return changed_tests
 
     changed_files = callo(["git", "diff", "--name-only", base_commit]).splitlines()
@@ -279,7 +279,7 @@ def create_task_list(evergreen_conf, buildvariant, suites, exclude_tasks):
 
     evg_buildvariant = evergreen_conf.get_variant(buildvariant)
     if not evg_buildvariant:
-        print "Buildvariant", buildvariant, "not found in", evergreen_conf.path
+        print("Buildvariant", buildvariant, "not found in", evergreen_conf.path)
         sys.exit(1)
 
     # Find all the buildvariant task's resmoke_args.
@@ -366,9 +366,9 @@ def main():
         evergreen_conf = evergreen.EvergreenProjectConfig(values.evergreen_file)
 
         if values.buildvariant is None:
-            print "Option buildVariant must be specified to find changed tests.\n", \
+            print("Option buildVariant must be specified to find changed tests.\n", \
                   "Select from the following: \n" \
-                  "\t", "\n\t".join(sorted(evergreen_conf.variant_names))
+                  "\t", "\n\t".join(sorted(evergreen_conf.variant_names)))
             sys.exit(1)
 
         changed_tests = find_changed_tests(values.branch,
@@ -380,7 +380,7 @@ def main():
         changed_tests = filter_tests(changed_tests, exclude_tests)
         # If there are no changed tests, exit cleanly.
         if not changed_tests:
-            print "No new or modified tests found."
+            print("No new or modified tests found.")
             _write_report_file({}, values.test_list_outfile)
             sys.exit(0)
         suites = resmokelib.parser.get_suites(values, changed_tests)
@@ -403,7 +403,7 @@ def main():
             try:
                 subprocess.check_call(resmoke_cmd, shell=False)
             except subprocess.CalledProcessError as err:
-                print "Resmoke returned an error with task:", task
+                print("Resmoke returned an error with task:", task)
                 _save_report_data(test_results, values.report_file, task)
                 _write_report_file(test_results, values.report_file)
                 sys.exit(err.returncode)
diff --git a/buildscripts/cleanbb.py b/buildscripts/cleanbb.py
index b599dc8..485109c 100644
--- a/buildscripts/cleanbb.py
+++ b/buildscripts/cleanbb.py
@@ -79,7 +79,7 @@ def tryToRemove(path):
 
 def cleanup( root , nokill ):
     if nokill:
-        print "nokill requested, not killing anybody"
+        print("nokill requested, not killing anybody")
     else:
         if killprocs( root=root ) > 0:
             time.sleep(3)
diff --git a/buildscripts/errorcodes.py b/buildscripts/errorcodes.py
index cc46789..a328cd0 100755
--- a/buildscripts/errorcodes.py
+++ b/buildscripts/errorcodes.py
@@ -9,7 +9,7 @@ Optionally replaces zero codes in source code with new distinct values.
 import bisect
 import os
 import sys
-import utils
+from . import utils
 from collections import defaultdict, namedtuple
 from optparse import OptionParser
 
@@ -66,9 +66,9 @@ def parseSourceFiles( callback ):
 
     for sourceFile in utils.getAllSourceFiles(prefix='src/mongo/'):
         if list_files:
-            print 'scanning file: ' + sourceFile
+            print('scanning file: ' + sourceFile)
 
-        with open(sourceFile) as f:
+        with open(sourceFile,encoding="utf-8") as f:
             text = f.read()
 
             if not any([zz in text for zz in quick]):
@@ -159,7 +159,7 @@ def readErrorCodes():
 
     parseSourceFiles( checkDups )
 
-    if seen.has_key("0"):
+    if "0" in seen:
         code = "0"
         bad = seen[code]
         errors.append( bad )
@@ -189,19 +189,19 @@ def replaceBadCodes( errors, nextCode ):
 
     for loc in skip_errors:
         line, col = getLineAndColumnForPosition(loc)
-        print ("SKIPPING NONZERO code=%s: %s:%d:%d"
+        print( "SKIPPING NONZERO code=%s: %s:%d:%d"
                 % (loc.code, loc.sourceFile, line, col))
 
     # Dedupe, sort, and reverse so we don't have to update offsets as we go.
     for assertLoc in reversed(sorted(set(zero_errors))):
         (sourceFile, byteOffset, lines, code) = assertLoc
         lineNum, _ = getLineAndColumnForPosition(assertLoc)
-        print "UPDATING_FILE: %s:%s" % (sourceFile, lineNum)
+        print("UPDATING_FILE: %s:%s" % (sourceFile, lineNum))
 
         ln = lineNum - 1
 
         with open(sourceFile, 'r+') as f:
-            print "LINE_%d_BEFORE:%s" % (lineNum, f.readlines()[ln].rstrip())
+            print("LINE_%d_BEFORE:%s" % (lineNum, f.readlines()[ln].rstrip()))
 
             f.seek(0)
             text = f.read()
@@ -212,7 +212,7 @@ def replaceBadCodes( errors, nextCode ):
             f.write(text[byteOffset+1:])
             f.seek(0)
 
-            print "LINE_%d_AFTER :%s" % (lineNum, f.readlines()[ln].rstrip())
+            print("LINE_%d_AFTER :%s" % (lineNum, f.readlines()[ln].rstrip()))
         nextCode += 1
 
 
@@ -281,7 +281,7 @@ def main():
     elif options.replace:
         replaceBadCodes(errors, next)
     else:
-        print ERROR_HELP
+        print(ERROR_HELP)
         sys.exit(1)
 
 
diff --git a/buildscripts/idl/idl/syntax.py b/buildscripts/idl/idl/syntax.py
index 492a7b9..1ef0313 100644
--- a/buildscripts/idl/idl/syntax.py
+++ b/buildscripts/idl/idl/syntax.py
@@ -95,8 +95,7 @@ def _item_and_type(dic):
     # type: (Dict[Any, List[Any]]) -> Iterator[Tuple[Any, Any]]
     """Return an Iterator of (key, value) pairs from a dictionary."""
     return itertools.chain.from_iterable((_zip_scalar(value, key)
-                                          for (key, value) in dic.viewitems()))
-
+                                          for (key, value) in dic.items()))
 
 class SymbolTable(object):
     """
diff --git a/buildscripts/make_archive.py b/buildscripts/make_archive.py
index 2671fa5..1233838 100755
--- a/buildscripts/make_archive.py
+++ b/buildscripts/make_archive.py
@@ -95,14 +95,14 @@ def make_tar_archive(opts):
         enclosing_file_directory = os.path.dirname(temp_file_location)
         if not os.path.exists(enclosing_file_directory):
             os.makedirs(enclosing_file_directory)
-        print "copying %s => %s" % (input_filename, temp_file_location)
+        print("copying %s => %s" % (input_filename, temp_file_location))
         if os.path.isdir(input_filename):
             shutil.copytree(input_filename, temp_file_location)
         else:
             shutil.copy2(input_filename, temp_file_location)
         tar_command.append(preferred_filename)
 
-    print " ".join(tar_command)
+    print(" ".join(tar_command))
     # execute the full tar command
     run_directory = os.path.join(os.getcwd(), enclosing_archive_directory)
     proc = Popen(tar_command, stdout=PIPE, stderr=STDOUT, bufsize=0, cwd=run_directory)
diff --git a/buildscripts/make_vcxproj.py b/buildscripts/make_vcxproj.py
index e4c2d7a..0e427b0 100644
--- a/buildscripts/make_vcxproj.py
+++ b/buildscripts/make_vcxproj.py
@@ -241,7 +241,7 @@ class ProjFileGenerator(object):
 
 def main():
     if len(sys.argv) != 2:
-        print r"Usage: python buildscripts\make_vcxproj.py FILE_NAME"
+        print(r"Usage: python buildscripts\make_vcxproj.py FILE_NAME")
         return
 
     with ProjFileGenerator(sys.argv[1]) as projfile:
diff --git a/buildscripts/msitrim.py b/buildscripts/msitrim.py
index 45ca8d4..b5781ed 100644
--- a/buildscripts/msitrim.py
+++ b/buildscripts/msitrim.py
@@ -29,7 +29,7 @@ def exec_update(query, column, value):
     view.Close()
 
 
-print "Trimming MSI"
+print("Trimming MSI")
 
 db = msilib.OpenDatabase(args.file.name, msilib.MSIDBOPEN_DIRECT)
 
diff --git a/buildscripts/packager-enterprise.py b/buildscripts/packager-enterprise.py
index 50d54f8..3afc7c6 100755
--- a/buildscripts/packager-enterprise.py
+++ b/buildscripts/packager-enterprise.py
@@ -153,7 +153,7 @@ def main(argv):
     if prefix is None:
       prefix=tempfile.mkdtemp()
 
-    print "Working in directory %s" % prefix
+    print("Working in directory %s" % prefix)
 
     os.chdir(prefix)
     try:
@@ -226,7 +226,7 @@ def make_package(distro, build_os, arch, spec, srcdir):
     # directory, so the debian directory is needed in all cases (and
     # innocuous in the debianoids' sdirs).
     for pkgdir in ["debian", "rpm"]:
-        print "Copying packaging files from %s to %s" % ("%s/%s" % (srcdir, pkgdir), sdir)
+        print("Copying packaging files from %s to %s" % ("%s/%s" % (srcdir, pkgdir), sdir))
         # FIXME: sh-dash-cee is bad. See if tarfile can do this.
         packager.sysassert(["sh", "-c", "(cd \"%s\" && git archive %s %s/ ) | (cd \"%s\" && tar xvf -)" % (srcdir, spec.metadata_gitspec(), pkgdir, sdir)])
     # Splat the binaries and snmp files under sdir.  The "build" stages of the
diff --git a/buildscripts/packager.py b/buildscripts/packager.py
index a43ba2e..97f6411 100755
--- a/buildscripts/packager.py
+++ b/buildscripts/packager.py
@@ -343,7 +343,7 @@ def main(argv):
     prefix = args.prefix
     if prefix is None:
       prefix = tempfile.mkdtemp()
-    print "Working in directory %s" % prefix
+    print("Working in directory %s" % prefix)
 
     os.chdir(prefix)
     try:
@@ -382,14 +382,14 @@ def crossproduct(*seqs):
 
 def sysassert(argv):
     """Run argv and assert that it exited with status 0."""
-    print "In %s, running %s" % (os.getcwd(), " ".join(argv))
+    print("In %s, running %s" % (os.getcwd(), " ".join(argv)))
     sys.stdout.flush()
     sys.stderr.flush()
     assert(subprocess.Popen(argv).wait()==0)
 
 def backtick(argv):
     """Run argv and return its output string."""
-    print "In %s, running %s" % (os.getcwd(), " ".join(argv))
+    print("In %s, running %s" % (os.getcwd(), " ".join(argv)))
     sys.stdout.flush()
     sys.stderr.flush()
     return subprocess.Popen(argv, stdout=subprocess.PIPE).communicate()[0]
@@ -421,7 +421,7 @@ def unpack_binaries_into(build_os, arch, spec, where):
         sysassert(["tar", "xvzf", rootdir+"/"+tarfile(build_os, arch, spec)])
         release_dir = glob('mongodb-linux-*')[0]
         for releasefile in "bin", "LICENSE-Community.txt", "README", "THIRD-PARTY-NOTICES", "THIRD-PARTY-NOTICES.gotools", "MPL-2":
-            print "moving file: %s/%s" % (release_dir, releasefile)
+            print("moving file: %s/%s" % (release_dir, releasefile))
             os.rename("%s/%s" % (release_dir, releasefile), releasefile)
         os.rmdir(release_dir)
     except Exception:
@@ -441,7 +441,7 @@ def make_package(distro, build_os, arch, spec, srcdir):
     # directory, so the debian directory is needed in all cases (and
     # innocuous in the debianoids' sdirs).
     for pkgdir in ["debian", "rpm"]:
-        print "Copying packaging files from %s to %s" % ("%s/%s" % (srcdir, pkgdir), sdir)
+        print("Copying packaging files from %s to %s" % ("%s/%s" % (srcdir, pkgdir), sdir))
         # FIXME: sh-dash-cee is bad. See if tarfile can do this.
         sysassert(["sh", "-c", "(cd \"%s\" && tar cf - %s/ ) | (cd \"%s\" && tar xvf -)" % (srcdir, pkgdir, sdir)])
     # Splat the binaries under sdir.  The "build" stages of the
diff --git a/buildscripts/resmokelib/core/process.py b/buildscripts/resmokelib/core/process.py
index 03fb849..e70f90a 100644
--- a/buildscripts/resmokelib/core/process.py
+++ b/buildscripts/resmokelib/core/process.py
@@ -196,8 +196,8 @@ class Process(object):
                 finally:
                     win32api.CloseHandle(mongo_signal_handle)
 
-                print "Failed to cleanly exit the program, calling TerminateProcess() on PID: " +\
-                    str(self._process.pid)
+                print("Failed to cleanly exit the program, calling TerminateProcess() on PID: " +\
+                    str(self._process.pid))
 
             # Adapted from implementation of Popen.terminate() in subprocess.py of Python 2.7
             # because earlier versions do not catch exceptions.
diff --git a/buildscripts/smoke.py b/buildscripts/smoke.py
index 4fdb01d..481916d 100755
--- a/buildscripts/smoke.py
+++ b/buildscripts/smoke.py
@@ -133,17 +133,17 @@ class NullMongod(object):
 
 
 def dump_stacks(signal, frame):
-    print "======================================"
-    print "DUMPING STACKS due to SIGUSR1 signal"
-    print "======================================"
+    print("======================================")
+    print("DUMPING STACKS due to SIGUSR1 signal")
+    print("======================================")
     threads = threading.enumerate();
 
-    print "Total Threads: " + str(len(threads))
+    print("Total Threads: " + str(len(threads)))
 
     for id, stack in sys._current_frames().items():
-        print "Thread %d" % (id)
-        print "".join(traceback.format_stack(stack))
-    print "======================================"
+        print("Thread %d" % (id))
+        print("".join(traceback.format_stack(stack)))
+    print("======================================")
 
 
 def buildlogger(cmd, is_global=False):
@@ -196,8 +196,8 @@ class mongod(NullMongod):
         try:
             self.check_mongo_port(int(port))
             return True
-        except Exception,e:
-            print >> sys.stderr, e
+        except Exception as e:
+            print(e, file=sys.stderr)
             return False
         
     def did_mongod_start(self, port=mongod_port, timeout=300):
@@ -207,14 +207,14 @@ class mongod(NullMongod):
             if is_up:
                 return True
             timeout = timeout - 1
-        print >> sys.stderr, "timeout starting mongod"
+        print( "timeout starting mongod", file=sys.stderr)
         return False
 
     def start(self):
         global mongod_port
         global mongod
         if self.proc:
-            print >> sys.stderr, "probable bug: self.proc already set in start()"
+            print( "probable bug: self.proc already set in start()", file=sys.stderr)
             return
         self.ensure_test_dirs()
         dir_name = smoke_db_prefix + "/data/db/sconsTests/"
@@ -270,7 +270,7 @@ class mongod(NullMongod):
                      '--sslAllowConnectionsWithoutCertificates']
         if self.kwargs.get('rlp_path'):
             argv += ['--basisTechRootDirectory', self.kwargs.get('rlp_path')]
-        print "running " + " ".join(argv)
+        print( "running " + " ".join(argv))
         self.proc = self._start(buildlogger(argv, is_global=True))
 
         # If the mongod process is spawned under buildlogger.py, then the first line of output
@@ -352,7 +352,7 @@ class mongod(NullMongod):
 
     def stop(self):
         if not self.proc:
-            print >> sys.stderr, "probable bug: self.proc unset in stop()"
+            print("probable bug: self.proc unset in stop()", file=sys.stderr)
             return
         try:
             if os.sys.platform == "win32" and self.job_object is not None:
@@ -407,9 +407,9 @@ class mongod(NullMongod):
                 self.proc.terminate()
             else:
                 os.kill(self.proc.pid, 15)
-        except Exception, e:
-            print >> sys.stderr, "error shutting down mongod"
-            print >> sys.stderr, e
+        except Exception as e:
+            print( "error shutting down mongod", file=sys.stderr)
+            print(e, file=sys.stderr)
         self.proc.wait()
 
         if self._stdout_pipe is not None:
@@ -427,9 +427,9 @@ class mongod(NullMongod):
             raise(Exception('mongod process exited with non-zero code %d' % retcode))
 
     def wait_for_repl(self):
-        print "Awaiting replicated (w:2, wtimeout:5min) insert (port:" + str(self.port) + ")"
+        print( "Awaiting replicated (w:2, wtimeout:5min) insert (port:" + str(self.port) + ")")
         MongoClient(port=self.port).testing.smokeWait.insert({}, w=2, wtimeout=5*60*1000)
-        print "Replicated write completed -- done wait_for_repl"
+        print("Replicated write completed -- done wait_for_repl")
 
 class Bug(Exception):
     def __str__(self):
@@ -506,7 +506,7 @@ def check_db_hashes(master, slave):
                 mOplog = mTestDB.connection.local[oplog];
                 oplog_entries = list(mOplog.find({"$or": [{"ns":mTestDB[coll].full_name}, \
                                                           {"op":"c"}]}).sort("$natural", 1))
-                print "oplog for %s" % mTestDB[coll].full_name
+                print("oplog for %s" % mTestDB[coll].full_name)
                 for doc in oplog_entries:
                     pprint.pprint(doc, width=200)
 
@@ -745,7 +745,7 @@ def runTest(test, result):
 
     is_mongod_still_up = test_mongod.is_mongod_up(mongod_port)
     if start_mongod and not is_mongod_still_up:
-        print "mongod is not running after test"
+        print("mongod is not running after test")
         result["mongod_running_at_end"] = is_mongod_still_up;
         raise TestServerFailure(path)
 
@@ -754,7 +754,7 @@ def runTest(test, result):
     if r != 0:
         raise TestExitFailure(path, r)
 
-    print ""
+    print("")
 
 def run_tests(tests):
     # FIXME: some suites of tests start their own mongod, so don't
@@ -825,7 +825,7 @@ def run_tests(tests):
                 result = primary.admin.command("ismaster");
                 ismaster = result["ismaster"]
                 if not ismaster:
-                    print "waiting for primary to be available ..."
+                    print("waiting for primary to be available ...")
                     time.sleep(.2)
             
             secondaryUp = False
@@ -835,7 +835,7 @@ def run_tests(tests):
                 result = sConn.admin.command("ismaster");
                 secondaryUp = result["secondary"]
                 if not secondaryUp:
-                    print "waiting for secondary to be available ..."
+                    print("waiting for secondary to be available ...")
                     time.sleep(.2)
 
         if small_oplog or small_oplog_rs:
@@ -857,7 +857,7 @@ def run_tests(tests):
                 if skipTest(test_path):
                     test_result["status"] = "skip"
 
-                    print "skipping " + test_path
+                    print("skipping " + test_path)
                 else:
                     fails.append(test)
                     runTest(test, test_result)
@@ -904,7 +904,7 @@ def run_tests(tests):
                 test_result["status"] = "fail"
                 test_report["results"].append( test_result )
                 try:
-                    print f
+                    print(f)
                     # Record the failing test and re-raise.
                     losers[f.path] = f.status
                     raise f
@@ -925,51 +925,51 @@ def run_tests(tests):
 def check_and_report_replication_dbhashes():
     def missing(lst, src, dst):
         if lst:
-            print """The following collections were present in the %s but not the %s
-at the end of testing:""" % (src, dst)
+            print("""The following collections were present in the %s but not the %s
+at the end of testing:""" % (src, dst))
             for db in lst:
-                print db
+                print(db)
 
     missing(lost_in_slave, "master", "slave")
     missing(lost_in_master, "slave", "master")
     if screwy_in_slave:
-        print """The following collections have different hashes in the master and slave:"""
+        print("""The following collections have different hashes in the master and slave:""")
         for coll in screwy_in_slave.keys():
             stats = screwy_in_slave[coll]
             # Counts are "approx" because they are collected after the dbhash runs and may not
             # reflect the states of the collections that were hashed. If the hashes differ, one
             # possibility is that a test exited with writes still in-flight.
-            print "collection: %s\t (master/slave) hashes: %s/%s counts (approx): %i/%i" % (coll, stats['hashes']['master'], stats['hashes']['slave'], stats['counts']['master'], stats['counts']['slave'])
+            print("collection: %s\t (master/slave) hashes: %s/%s counts (approx): %i/%i" % (coll, stats['hashes']['master'], stats['hashes']['slave'], stats['counts']['master'], stats['counts']['slave']))
             if "docs" in stats:
                 if (("master" in stats["docs"] and len(stats["docs"]["master"]) == 0) and
                     ("slave" in stats["docs"] and len(stats["docs"]["slave"]) == 0)):
-                    print "All docs matched!"
+                    print("All docs matched!")
                 else:
-                    print "Different Docs"
-                    print "Master docs:"
+                    print("Different Docs")
+                    print("Master docs:")
                     pprint.pprint(stats["docs"]["master"], indent=2)
-                    print "Slave docs:"
+                    print("Slave docs:")
                     pprint.pprint(stats["docs"]["slave"], indent=2)
             if "error-docs" in stats:
-                print "Error getting docs to diff:"
+                print("Error getting docs to diff:")
                 pprint.pprint(stats["error-docs"])
         return True
 
     if (small_oplog or small_oplog_rs) and not (lost_in_master or lost_in_slave or screwy_in_slave):
-        print "replication ok for %d collections" % (len(replicated_collections))
+        print("replication ok for %d collections" % (len(replicated_collections)))
 
     return False
 
 
 def report():
-    print "%d tests succeeded" % len(winners)
+    print("%d tests succeeded" % len(winners))
     num_missed = len(tests) - (len(winners) + len(losers.keys()))
     if num_missed:
-        print "%d tests didn't get run" % num_missed
+        print("%d tests didn't get run" % num_missed)
     if losers:
-        print "The following tests failed (with exit code):"
+        print("The following tests failed (with exit code):")
         for loser in losers:
-            print "%s\t%d" % (loser, losers[loser])
+            print("%s\t%d" % (loser, losers[loser]))
 
     test_result = { "start": time.time() }
     if check_and_report_replication_dbhashes():
@@ -1244,7 +1244,7 @@ def run_old_fails():
         return # This counts as passing so we will run all tests
 
     if ('version' not in state or state['version'] != file_version()):
-        print "warning: old version of failfile.smoke detected. skipping recent fails"
+        print("warning: old version of failfile.smoke detected. skipping recent fails")
         clear_failfile()
         return
 
@@ -1308,7 +1308,7 @@ def main():
     try:
         signal.signal(signal.SIGUSR1, dump_stacks)
     except AttributeError:
-        print "Cannot catch signals on Windows"
+        print("Cannot catch signals on Windows")
 
     parser = OptionParser(usage="usage: smoke.py [OPTIONS] ARGS*")
     parser.add_option('--mode', dest='mode', default='suite',
@@ -1450,11 +1450,11 @@ def main():
 
     if options.ignore_files != None :
         ignore_patt = re.compile( options.ignore_files )
-        print "Ignoring files with pattern: ", ignore_patt
+        print("Ignoring files with pattern: ", ignore_patt)
 
         def ignore_test( test ):
             if ignore_patt.search( test[0] ) != None:
-                print "Ignoring test ", test[0]
+                print("Ignoring test ", test[0])
                 return False
             else:
                 return True
@@ -1462,7 +1462,7 @@ def main():
         tests = filter( ignore_test, tests )
 
     if not tests:
-        print "warning: no tests specified"
+        print("warning: no tests specified")
         return
 
     if options.with_cleanbb:
diff --git a/buildscripts/utils.py b/buildscripts/utils.py
index 69a7892..8103cd0 100644
--- a/buildscripts/utils.py
+++ b/buildscripts/utils.py
@@ -122,7 +122,7 @@ def getprocesslist():
     raw = ""
     try:
         raw = execsys( "/bin/ps axww" )[0]
-    except Exception,e:
+    except Exception as e:
         print( "can't get processlist: " + str( e ) )
 
     r = re.compile( "[\r\n]+" )
@@ -176,7 +176,7 @@ def didMongodStart( port=27017 , timeout=20 ):
         try:
             checkMongoPort( port )
             return True
-        except Exception,e:
+        except Exception as e:
             print( e )
             timeout = timeout - 1
     return False
diff --git a/site_scons/libdeps.py b/site_scons/libdeps.py
index 632ed29..e0a001c 100644
--- a/site_scons/libdeps.py
+++ b/site_scons/libdeps.py
@@ -122,7 +122,7 @@ def __get_libdeps(node):
                 marked.add(n.target_node)
                 tsorted.append(n.target_node)
 
-            except DependencyCycleError, e:
+            except DependencyCycleError as e:
                 if len(e.cycle_nodes) == 1 or e.cycle_nodes[0] != e.cycle_nodes[-1]:
                     e.cycle_nodes.insert(0, n.target_node)
                 raise
@@ -150,7 +150,7 @@ def __get_syslibdeps(node):
         for lib in __get_libdeps(node):
             for syslib in node.get_env().Flatten(lib.get_env().get(syslibdeps_env_var, [])):
                 if syslib:
-                    if type(syslib) in (str, unicode) and syslib.startswith(missing_syslibdep):
+                    if type(syslib) in (bytes, str) and syslib.startswith(missing_syslibdep):
                         print("Target '%s' depends on the availability of a "
                               "system provided library for '%s', "
                               "but no suitable library was found during configuration." %
@@ -209,7 +209,7 @@ def get_syslibdeps(source, target, env, for_signature):
         # they're believed to represent library short names, that should be prefixed with -l
         # or the compiler-specific equivalent.  I.e., 'm' becomes '-lm', but 'File("m.a") is passed
         # through whole cloth.
-        if type(d) in (str, unicode):
+        if type(d) in (bytes, str):
             result.append('%s%s%s' % (lib_link_prefix, d, lib_link_suffix))
         else:
             result.append(d)
diff --git a/site_scons/mongo/__init__.py b/site_scons/mongo/__init__.py
index 510bd7b..f774780 100644
--- a/site_scons/mongo/__init__.py
+++ b/site_scons/mongo/__init__.py
@@ -5,4 +5,4 @@
 def print_build_failures():
     from SCons.Script import GetBuildFailures
     for bf in GetBuildFailures():
-        print "%s failed: %s" % (bf.node, bf.errstr)
+        print("%s failed: %s" % (bf.node, bf.errstr))
diff --git a/site_scons/mongo/generators.py b/site_scons/mongo/generators.py
index c07e86a..91d0a4d 100644
--- a/site_scons/mongo/generators.py
+++ b/site_scons/mongo/generators.py
@@ -1,6 +1,6 @@
 # -*- mode: python; -*-
 
-import md5
+from hashlib import md5
 
 # Default and alternative generator definitions go here.
 
@@ -44,7 +44,7 @@ def default_variant_dir_generator(target, source, env, for_signature):
 
     # Hash the named options and their values, and take the first 8 characters of the hash as
     # the variant name
-    hasher = md5.md5()
+    hasher = md5()
     for option in variant_options:
         hasher.update(option)
         hasher.update(str(env.GetOption(option)))
diff --git a/site_scons/site_tools/distsrc.py b/site_scons/site_tools/distsrc.py
index 861f5d9..8768300 100644
--- a/site_scons/site_tools/distsrc.py
+++ b/site_scons/site_tools/distsrc.py
@@ -20,7 +20,10 @@ import shutil
 import tarfile
 import time
 import zipfile
-import StringIO
+try:
+    import StringIO
+except ImportError:
+    from io import StringIO
 
 from distutils.spawn import find_executable
 
@@ -82,7 +85,7 @@ class DistSrcTarArchive(DistSrcArchive):
 
     def append_file_contents(self, filename, file_contents,
             mtime=time.time(),
-            mode=0644,
+            mode=0o644,
             uname="root",
             gname="root"):
         file_metadata = tarfile.TarInfo(name=filename)
@@ -119,7 +122,7 @@ class DistSrcZipArchive(DistSrcArchive):
             name=key,
             size=item_data.file_size,
             mtime=time.mktime(fixed_time),
-            mode=0775 if is_dir else 0664,
+            mode=0o775 if is_dir else 0o664,
             type=tarfile.DIRTYPE if is_dir else tarfile.REGTYPE,
             uid=0,
             gid=0,
@@ -129,7 +132,7 @@ class DistSrcZipArchive(DistSrcArchive):
 
     def append_file_contents(self, filename, file_contents,
             mtime=time.time(),
-            mode=0644,
+            mode=0o644,
             uname="root",
             gname="root"):
         self.archive_file.writestr(filename, file_contents)
@@ -139,7 +142,7 @@ class DistSrcZipArchive(DistSrcArchive):
 
 def build_error_action(msg):
     def error_stub(target=None, source=None, env=None):
-        print msg
+        print(msg)
         env.Exit(1)
     return [ error_stub ]
 
@@ -162,7 +165,7 @@ def distsrc_action_generator(source, target, env, for_signature):
 
     target_ext = str(target[0])[-3:]
     if not target_ext in [ 'zip', 'tar' ]:
-        print "Invalid file format for distsrc. Must be tar or zip file"
+        print("Invalid file format for distsrc. Must be tar or zip file")
         env.Exit(1)
 
     git_cmd = "\"%s\" archive --format %s --output %s --prefix ${MONGO_DIST_SRC_PREFIX} HEAD" % (
diff --git a/site_scons/site_tools/idl_tool.py b/site_scons/site_tools/idl_tool.py
index 78bedfa..6303a5a 100755
--- a/site_scons/site_tools/idl_tool.py
+++ b/site_scons/site_tools/idl_tool.py
@@ -47,7 +47,8 @@ def idl_scanner(node, env, path):
 
     deps_list = deps_str.splitlines()
 
-    nodes_deps_list = [ env.File(d) for d in deps_list]
+    # scons likes ascii encoded "files" so lets provide one to it...
+    nodes_deps_list = [ env.File(d.decode("ascii", "ignore")) for d in deps_list]
     nodes_deps_list.extend(env.Glob('#buildscripts/idl/*.py'))
     nodes_deps_list.extend(env.Glob('#buildscripts/idl/idl/*.py'))
 
diff --git a/site_scons/site_tools/jstoh.py b/site_scons/site_tools/jstoh.py
index dc90b32..7a0d213 100644
--- a/site_scons/site_tools/jstoh.py
+++ b/site_scons/site_tools/jstoh.py
@@ -39,17 +39,17 @@ def jsToHeader(target, source):
 
     text = '\n'.join(h)
 
-    print "writing: %s" % outFile
+    print( "writing: %s" % outFile)
     with open(outFile, 'wb') as out:
         try:
-            out.write(text)
+            out.write(text.encode(encoding='utf_8',errors='strict'))
         finally:
             out.close()
 
 
 if __name__ == "__main__":
     if len(sys.argv) < 3:
-        print "Must specify [target] [source] "
+        print("Must specify [target] [source] ")
         sys.exit(1)
 
     jsToHeader(sys.argv[1], sys.argv[2:])
diff --git a/site_scons/site_tools/mongo_benchmark.py b/site_scons/site_tools/mongo_benchmark.py
index 7c12627..16fc104 100644
--- a/site_scons/site_tools/mongo_benchmark.py
+++ b/site_scons/site_tools/mongo_benchmark.py
@@ -14,7 +14,7 @@ def benchmark_list_builder_action(env, target, source):
     ofile = open(str(target[0]), 'wb')
     try:
         for s in _benchmarks:
-            print '\t' + str(s)
+            print('\t' + str(s))
             ofile.write('%s\n' % s)
     finally:
         ofile.close()
diff --git a/site_scons/site_tools/mongo_integrationtest.py b/site_scons/site_tools/mongo_integrationtest.py
index ff9a5f4..dcb0078 100644
--- a/site_scons/site_tools/mongo_integrationtest.py
+++ b/site_scons/site_tools/mongo_integrationtest.py
@@ -15,7 +15,7 @@ def integration_test_list_builder_action(env, target, source):
     ofile = open(str(target[0]), 'wb')
     try:
         for s in _integration_tests:
-            print '\t' + str(s)
+            print('\t' + str(s))
             ofile.write('%s\n' % s)
     finally:
         ofile.close()
diff --git a/site_scons/site_tools/mongo_unittest.py b/site_scons/site_tools/mongo_unittest.py
index ec99ab2..288e1df 100644
--- a/site_scons/site_tools/mongo_unittest.py
+++ b/site_scons/site_tools/mongo_unittest.py
@@ -14,7 +14,7 @@ def unit_test_list_builder_action(env, target, source):
     ofile = open(str(target[0]), 'wb')
     try:
         for s in _unittests:
-            print '\t' + str(s)
+            print('\t' + str(s))
             ofile.write('%s\n' % s)
     finally:
         ofile.close()
diff --git a/site_scons/site_tools/thin_archive.py b/site_scons/site_tools/thin_archive.py
index 511c0ef..9baf3d0 100644
--- a/site_scons/site_tools/thin_archive.py
+++ b/site_scons/site_tools/thin_archive.py
@@ -41,7 +41,7 @@ def exists(env):
     for line in pipe.stdout:
         if isgnu:
             continue  # consume all data
-        isgnu = re.search(r'^GNU ar', line)
+        isgnu = re.search(r'^GNU ar', str(line))
 
     return bool(isgnu)
 
diff --git a/src/mongo/SConscript b/src/mongo/SConscript
index 435fbd2..31a6d99 100644
--- a/src/mongo/SConscript
+++ b/src/mongo/SConscript
@@ -157,7 +157,7 @@ js_engine_ver = get_option("js-engine") if get_option("server-js") == "on" else
 
 # On windows, we need to escape the backslashes in the command-line
 # so that windows paths look okay.
-cmd_line = " ".join(sys.argv).encode('string-escape')
+cmd_line = " ".join(sys.argv).encode('unicode_escape')
 if env.TargetOSIs('windows'):
     cmd_line = cmd_line.replace('\\', r'\\')
 
@@ -612,7 +612,7 @@ env.Append(MODULE_BANNERS = [distsrc.File('README'),
                              distsrc.File('MPL-2')])
 
 # If no module has introduced a file named LICENSE.txt, then inject the license.
-if sum(itertools.imap(lambda x: x.name == "LICENSE.txt", env['MODULE_BANNERS'])) == 0:
+if sum(map(lambda x: x.name == "LICENSE.txt", env['MODULE_BANNERS'])) == 0:
     env.Append(MODULE_BANNERS = [distsrc.File('LICENSE-Community.txt')])
 
 # All module banners get staged to the top level of the tarfile, so we
diff --git a/src/mongo/base/generate_error_codes.py b/src/mongo/base/generate_error_codes.py
index 5de9e52..9e3b592 100644
--- a/src/mongo/base/generate_error_codes.py
+++ b/src/mongo/base/generate_error_codes.py
@@ -95,7 +95,7 @@ def main(argv):
                 )
 
         with open(output, 'wb') as outfile:
-            outfile.write(text)
+            outfile.write(bytes(text,encoding='utf-8'))
 
 def die(message=None):
     sys.stderr.write(message or "Fatal error\n")
diff --git a/src/mongo/db/auth/generate_action_types.py b/src/mongo/db/auth/generate_action_types.py
index 3d3a36c..7b07004 100755
--- a/src/mongo/db/auth/generate_action_types.py
+++ b/src/mongo/db/auth/generate_action_types.py
@@ -232,7 +232,7 @@ def hasDuplicateActionTypes(actionTypes):
     prevActionType = sortedActionTypes[0]
     for actionType in sortedActionTypes[1:]:
         if actionType == prevActionType:
-            print 'Duplicate actionType %s\n' % actionType
+            print('Duplicate actionType %s\n' % actionType)
             didFail = True
         prevActionType = actionType
 
@@ -245,7 +245,7 @@ def parseActionTypesFromFile(actionTypesFilename):
 
 if __name__ == "__main__":
     if len(sys.argv) != 4:
-        print "Usage: generate_action_types.py <path to action_types.txt> <header file path> <source file path>"
+        print("Usage: generate_action_types.py <path to action_types.txt> <header file path> <source file path>")
         sys.exit(-1)
 
     actionTypes = parseActionTypesFromFile(sys.argv[1])
diff --git a/src/mongo/db/fts/generate_stop_words.py b/src/mongo/db/fts/generate_stop_words.py
index e0dc801..5c153ab 100644
--- a/src/mongo/db/fts/generate_stop_words.py
+++ b/src/mongo/db/fts/generate_stop_words.py
@@ -19,39 +19,47 @@ namespace fts {
   void loadStopWordMap( StringMap< std::set< std::string > >* m );
 }
 }
-""" )
+""".encode(encoding='utf_8',errors='strict') )
     out.close()
 
 
 
     out = open( source, "wb" )
-    out.write( '#include "%s"' % header.rpartition( "/" )[2].rpartition( "\\" )[2] )
+    tmp_buf = '#include "%s"' % header.rpartition( "/" )[2].rpartition( "\\" )[2]
+    out.write( tmp_buf.encode(encoding='utf_8',errors='strict') )
+
+
     out.write( """
 namespace mongo {
 namespace fts {
 
   void loadStopWordMap( StringMap< std::set< std::string > >* m ) {
-
-""" )
+""".encode(encoding='utf_8',errors='strict') )
 
     for l_file in language_files:
         l = l_file.rpartition( "_" )[2].partition( "." )[0]
 
-        out.write( '  // %s\n' % l_file )
-        out.write( '  {\n' )
-        out.write( '   const char* const words[] = {\n' )
+        tmp_buf = """  // %s
+  {
+   const char* const words[] = {
+""" % l_file
+        out.write( tmp_buf.encode(encoding='utf_8',errors='strict') )
         for word in open( l_file, "rb" ):
-            out.write( '       "%s",\n' % word.strip() )
-        out.write( '   };\n' )
-        out.write( '   const size_t wordcnt = sizeof(words) / sizeof(words[0]);\n' )
-        out.write( '   std::set< std::string >& l = (*m)["%s"];\n' % l )
-        out.write( '   l.insert(&words[0], &words[wordcnt]);\n' )
-        out.write( '  }\n' )
+            out.write( '       "%s",\n'.encode(encoding='utf_8',errors='strict') % word.strip() )
+        tmp_buf="""
+   };
+   const size_t wordcnt = sizeof(words) / sizeof(words[0]);
+   std::set< std::string >& l = (*m)["%s"];
+   l.insert(&words[0], &words[wordcnt]);
+  }
+
+"""  % l
+        out.write( tmp_buf.encode(encoding='utf_8',errors='strict') )
     out.write( """
   }
 } // namespace fts
 } // namespace mongo
-""" )
+""".encode(encoding='utf_8',errors='strict') )
 
 
 if __name__ == "__main__":
diff --git a/src/mongo/db/fts/unicode/gen_casefold_map.py b/src/mongo/db/fts/unicode/gen_casefold_map.py
index 1900369..9e77417 100644
--- a/src/mongo/db/fts/unicode/gen_casefold_map.py
+++ b/src/mongo/db/fts/unicode/gen_casefold_map.py
@@ -22,7 +22,7 @@ def generate(unicode_casefold_file, target):
 
     case_mappings = {}
 
-    cf_file = open(unicode_casefold_file, 'rU')
+    cf_file = open(unicode_casefold_file, 'rU',encoding="utf-8")
 
     for line in cf_file:
         # Filter out blank lines and lines that start with #
diff --git a/src/mongo/db/query/collation/generate_icu_init_cpp.py b/src/mongo/db/query/collation/generate_icu_init_cpp.py
index a95740b..43b624d 100755
--- a/src/mongo/db/query/collation/generate_icu_init_cpp.py
+++ b/src/mongo/db/query/collation/generate_icu_init_cpp.py
@@ -85,8 +85,8 @@ def generate_cpp_file(data_file_path, cpp_file_path):
 #include "mongo/base/init.h"
 #include "mongo/util/assert_util.h"
 
-namespace mongo {
-namespace {
+namespace mongo {{
+namespace {{
 
 // alignas() is used here to ensure 16-alignment of ICU data.  See the following excerpt from the
 // ICU user guide (<http://userguide.icu-project.org/icudata#TOC-Alignment>):
@@ -97,24 +97,23 @@ namespace {
 // n-alignment of types of size n bytes (and crash on unaligned reads), other CPUs usually operate
 // faster on data that is aligned properly.  Some of the ICU code explicitly checks for proper
 // alignment."
-alignas(16) const uint8_t kRawData[] = {%(decimal_encoded_data)s};
+alignas(16) const uint8_t kRawData[] = {{ {decimal_encoded_data} }};
+}}  // namespace
 
-}  // namespace
-
-MONGO_INITIALIZER(LoadICUData)(InitializerContext* context) {
+MONGO_INITIALIZER(LoadICUData)(InitializerContext* context) {{
     UErrorCode status = U_ZERO_ERROR;
     udata_setCommonData(kRawData, &status);
     fassert(40088, U_SUCCESS(status));
     return Status::OK();
-}
+}}
 
-}  // namespace mongo
+}}  // namespace mongo
 '''
     decimal_encoded_data = ''
     with open(data_file_path, 'rb') as data_file:
-        decimal_encoded_data = ','.join([str(ord(byte)) for byte in data_file.read()])
+        decimal_encoded_data = ','.join([str(byte) for byte in data_file.read()])
     with open(cpp_file_path, 'wb') as cpp_file:
-        cpp_file.write(source_template % dict(decimal_encoded_data=decimal_encoded_data))
-
+        tmp_buf = source_template.format(decimal_encoded_data=decimal_encoded_data)
+        cpp_file.write(tmp_buf.encode(encoding='utf_8',errors='strict'))
 if __name__ == '__main__':
     main(sys.argv)
diff --git a/src/third_party/wiredtiger/SConstruct b/src/third_party/wiredtiger/SConstruct
index 2646d51..1d570e8 100644
--- a/src/third_party/wiredtiger/SConstruct
+++ b/src/third_party/wiredtiger/SConstruct
@@ -11,7 +11,7 @@ import distutils.sysconfig
 EnsureSConsVersion( 2, 0, 0 )
 
 if not os.sys.platform == "win32":
-    print ("SConstruct is only supported for Windows, use build_posix for other platforms")
+    print("SConstruct is only supported for Windows, use build_posix for other platforms")
     Exit(1)
 
 # Command line options
@@ -118,7 +118,7 @@ wtlibs = []
 
 conf = Configure(env)
 if not conf.CheckCHeader('stdlib.h'):
-    print 'stdlib.h must be installed!'
+    print('stdlib.h must be installed!')
     Exit(1)
 
 if useZlib:
@@ -128,7 +128,7 @@ if useZlib:
         conf.env.Append(CPPDEFINES=["HAVE_BUILTIN_EXTENSION_ZLIB"])
         wtlibs.append("zlib")
     else:
-        print 'zlib.h must be installed!'
+        print('zlib.h must be installed!')
         Exit(1)
 
 if useSnappy:
@@ -138,7 +138,7 @@ if useSnappy:
         conf.env.Append(CPPDEFINES=['HAVE_BUILTIN_EXTENSION_SNAPPY'])
         wtlibs.append("snappy")
     else:
-        print 'snappy-c.h must be installed!'
+        print('snappy-c.h must be installed!')
         Exit(1)
 
 if useLz4:
@@ -148,14 +148,14 @@ if useLz4:
         conf.env.Append(CPPDEFINES=['HAVE_BUILTIN_EXTENSION_LZ4'])
         wtlibs.append("lz4")
     else:
-        print 'lz4.h must be installed!'
+        print('lz4.h must be installed!')
         Exit(1)
 
 if useBdb:
     conf.env.Append(CPPPATH=[useBdb+ "/include"])
     conf.env.Append(LIBPATH=[useBdb+ "/lib"])
     if not conf.CheckCHeader('db.h'):
-        print 'db.h must be installed!'
+        print('db.h must be installed!')
         Exit(1)
 
 if useTcmalloc:
@@ -166,7 +166,7 @@ if useTcmalloc:
         conf.env.Append(CPPDEFINES=['HAVE_LIBTCMALLOC'])
         conf.env.Append(CPPDEFINES=['HAVE_POSIX_MEMALIGN'])
     else:
-        print 'tcmalloc.h must be installed!'
+        print('tcmalloc.h must be installed!')
         Exit(1)
 
 env = conf.Finish()
@@ -202,7 +202,7 @@ if (VERSION_MAJOR == None or
     VERSION_MINOR == None or
     VERSION_PATCH == None or
     VERSION_STRING == None):
-    print "Failed to find version variables in " + version_file
+    print("Failed to find version variables in " + version_file)
     Exit(1)
 
 wiredtiger_includes = """
@@ -322,7 +322,7 @@ if GetOption("lang-python"):
     # Check that this version of python is 64-bit
     #
     if sys.maxsize < 2**32:
-        print "The Python Interpreter must be 64-bit in order to build the python bindings"
+        print("The Python Interpreter must be 64-bit in order to build the python bindings")
         Exit(1)
 
     pythonEnv = env.Clone()
@@ -436,7 +436,7 @@ examples = [
 # WiredTiger Smoke Test support
 # Runs each test in a custom temporary directory
 def run_smoke_test(x):
-    print "Running Smoke Test: " + x
+    print("Running Smoke Test: " + x)
 
     # Make temp dir
     temp_dir = tempfile.mkdtemp(prefix="wt_home")
