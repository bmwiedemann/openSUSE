<package name="llamacpp" project="openSUSE:Factory">
  <title>llama.cpp</title>
  <description>The main goal of llama.cpp is to enable LLM inference with minimal setup and state-of-the-art performance on a wide variety of hardware - locally and in the cloud.</description>
  <devel project="science:machinelearning" package="llamacpp"/>
  <url>https://github.com/ggerganov/llama.cpp</url>
</package>
